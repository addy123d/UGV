{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8694046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:53:54.578726Z",
     "iopub.status.busy": "2023-08-19T11:53:54.578329Z",
     "iopub.status.idle": "2023-08-19T11:54:38.852722Z",
     "shell.execute_reply": "2023-08-19T11:54:38.851647Z"
    },
    "papermill": {
     "duration": 44.283095,
     "end_time": "2023-08-19T11:54:38.855132",
     "exception": false,
     "start_time": "2023-08-19T11:53:54.572037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification==0.1.7\n",
      "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification==0.1.7) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification==0.1.7) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from iterative-stratification==0.1.7) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.1.0)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.7\n",
      "tokenizers.__version__: 0.13.3\n",
      "transformers.__version__: 4.30.2\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "    # ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Tuple, List\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "os.system('pip install iterative-stratification==0.1.7')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('pip install -q transformers')\n",
    "os.system('pip install -q tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9779e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:38.866355Z",
     "iopub.status.busy": "2023-08-19T11:54:38.865768Z",
     "iopub.status.idle": "2023-08-19T11:54:38.878944Z",
     "shell.execute_reply": "2023-08-19T11:54:38.877855Z"
    },
    "papermill": {
     "duration": 0.020993,
     "end_time": "2023-08-19T11:54:38.881029",
     "exception": false,
     "start_time": "2023-08-19T11:54:38.860036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    experiment_name: str = 'default-starter-training/'\n",
    "    model: str = field(default=\"microsoft/deberta-v3-base\")\n",
    "    batch_size: int = field(default=8)\n",
    "    max_len: int = field(default=512)\n",
    "    epochs: int = field(default=4)\n",
    "    encoder_lr: float = field(default=2e-5)\n",
    "    decoder_lr: float = field(default=2e-5)\n",
    "    min_lr: float = field(default=1e-6)\n",
    "    scheduler: str = field(default='cosine')  # ['linear', 'cosine']\n",
    "    debug: bool = field(default=False)\n",
    "    apex: bool = field(default=True)\n",
    "    print_freq: int = field(default=20)\n",
    "    num_workers: int = field(default=4)\n",
    "    gradient_checkpointing: bool = field(default=True)\n",
    "    batch_scheduler: bool = field(default=True)\n",
    "    num_cycles: float = field(default=0.5)\n",
    "    num_warmup_steps: int = field(default=0)\n",
    "    eps: float = field(default=1e-6)\n",
    "    betas: Tuple[float, float] = field(default=(0.9, 0.999))\n",
    "    weight_decay: float = field(default=0.01)\n",
    "    gradient_accumulation_steps: int = field(default=1)\n",
    "    max_grad_norm: int = field(default=1000)\n",
    "    target_cols: List[str] = field(default_factory=lambda: ['content', 'wording'])\n",
    "    seed: int = field(default=42)\n",
    "    n_fold: int = field(default=4)\n",
    "    trn_fold: List[int] = field(default_factory=lambda: [0, 1, 2, 3])\n",
    "    train: bool = field(default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49276753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:38.891647Z",
     "iopub.status.busy": "2023-08-19T11:54:38.890924Z",
     "iopub.status.idle": "2023-08-19T11:54:38.896732Z",
     "shell.execute_reply": "2023-08-19T11:54:38.895873Z"
    },
    "papermill": {
     "duration": 0.013246,
     "end_time": "2023-08-19T11:54:38.898714",
     "exception": false,
     "start_time": "2023-08-19T11:54:38.885468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "OUTPUT_DIR = config.experiment_name\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11d3c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:38.909769Z",
     "iopub.status.busy": "2023-08-19T11:54:38.908932Z",
     "iopub.status.idle": "2023-08-19T11:54:38.928458Z",
     "shell.execute_reply": "2023-08-19T11:54:38.927625Z"
    },
    "papermill": {
     "duration": 0.027137,
     "end_time": "2023-08-19T11:54:38.930396",
     "exception": false,
     "start_time": "2023-08-19T11:54:38.903259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea60bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:38.941311Z",
     "iopub.status.busy": "2023-08-19T11:54:38.940481Z",
     "iopub.status.idle": "2023-08-19T11:54:39.068121Z",
     "shell.execute_reply": "2023-08-19T11:54:39.066929Z"
    },
    "papermill": {
     "duration": 0.136606,
     "end_time": "2023-08-19T11:54:39.071582",
     "exception": false,
     "start_time": "2023-08-19T11:54:38.934976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (7165, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text   content   wording\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...  0.205683  0.380538\n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme... -0.548304  0.506755\n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...  3.128928  4.231226\n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we... -0.210614 -0.471415\n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...  3.272894  3.219757"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: (4, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text\n",
       "0  000000ffffff    abc123  Example text 1\n",
       "1  111111eeeeee    def789  Example text 2\n",
       "2  222222cccccc    abc123  Example text 3\n",
       "3  333333dddddd    def789  Example text 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.shape: (4, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id  content  wording\n",
       "0  000000ffffff      0.0      0.0\n",
       "1  111111eeeeee      0.0      0.0\n",
       "2  222222cccccc      0.0      0.0\n",
       "3  333333dddddd      0.0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('../input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "test = pd.read_csv('../input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv')\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "display(train.head())\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "display(test.head())\n",
    "print(f\"submission.shape: {submission.shape}\")\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4814d2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.085404Z",
     "iopub.status.busy": "2023-08-19T11:54:39.083959Z",
     "iopub.status.idle": "2023-08-19T11:54:39.399821Z",
     "shell.execute_reply": "2023-08-19T11:54:39.398824Z"
    },
    "papermill": {
     "duration": 0.324796,
     "end_time": "2023-08-19T11:54:39.402151",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.077355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    1791\n",
       "1    1791\n",
       "2    1792\n",
       "3    1791\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = MultilabelStratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[config.target_cols])):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "    \n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc22f47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.415004Z",
     "iopub.status.busy": "2023-08-19T11:54:39.414680Z",
     "iopub.status.idle": "2023-08-19T11:54:39.419732Z",
     "shell.execute_reply": "2023-08-19T11:54:39.418730Z"
    },
    "papermill": {
     "duration": 0.013996,
     "end_time": "2023-08-19T11:54:39.422010",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.408014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    display(train.groupby('fold').size())\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274b5c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.434536Z",
     "iopub.status.busy": "2023-08-19T11:54:39.434276Z",
     "iopub.status.idle": "2023-08-19T11:54:39.443204Z",
     "shell.execute_reply": "2023-08-19T11:54:39.442204Z"
    },
    "papermill": {
     "duration": 0.017974,
     "end_time": "2023-08-19T11:54:39.445635",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.427661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(config, text):\n",
    "    inputs = config.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=config.max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, config, df):\n",
    "        self.config = config\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df[config.target_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.config, self.texts[item])\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeae9e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.458195Z",
     "iopub.status.busy": "2023-08-19T11:54:39.457928Z",
     "iopub.status.idle": "2023-08-19T11:54:39.472439Z",
     "shell.execute_reply": "2023-08-19T11:54:39.471513Z"
    },
    "papermill": {
     "duration": 0.023317,
     "end_time": "2023-08-19T11:54:39.474658",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.451341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, config, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(config.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            LOGGER.info(self.config)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(config.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "#         if self.config.gradient_checkpointing:\n",
    "#             self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 2)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9de9ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.487985Z",
     "iopub.status.busy": "2023-08-19T11:54:39.487215Z",
     "iopub.status.idle": "2023-08-19T11:54:39.494136Z",
     "shell.execute_reply": "2023-08-19T11:54:39.493266Z"
    },
    "papermill": {
     "duration": 0.015684,
     "end_time": "2023-08-19T11:54:39.496058",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.480374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Loss\n",
    "# ====================================================\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, reduction='mean', eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "        self.reduction = reduction\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
    "        if self.reduction == 'none':\n",
    "            loss = loss\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67fd4e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.509204Z",
     "iopub.status.busy": "2023-08-19T11:54:39.508727Z",
     "iopub.status.idle": "2023-08-19T11:54:39.516625Z",
     "shell.execute_reply": "2023-08-19T11:54:39.515652Z"
    },
    "papermill": {
     "duration": 0.016743,
     "end_time": "2023-08-19T11:54:39.518600",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.501857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e582b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.531736Z",
     "iopub.status.busy": "2023-08-19T11:54:39.531474Z",
     "iopub.status.idle": "2023-08-19T11:54:39.547698Z",
     "shell.execute_reply": "2023-08-19T11:54:39.546850Z"
    },
    "papermill": {
     "duration": 0.025177,
     "end_time": "2023-08-19T11:54:39.549629",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.524452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=config.apex):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if config.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % config.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % config.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd817e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.562786Z",
     "iopub.status.busy": "2023-08-19T11:54:39.562522Z",
     "iopub.status.idle": "2023-08-19T11:54:39.585482Z",
     "shell.execute_reply": "2023-08-19T11:54:39.584628Z"
    },
    "papermill": {
     "duration": 0.031983,
     "end_time": "2023-08-19T11:54:39.587501",
     "exception": false,
     "start_time": "2023-08-19T11:54:39.555518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(model_config, train_df, fold):\n",
    "    dir_output = os.path.join(OUTPUT_DIR, model_config.model.replace('/', '-'))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model)\n",
    "    tokenizer.save_pretrained(os.path.join(dir_output, 'tokenizer'))\n",
    "    model_config.tokenizer = tokenizer\n",
    "    \n",
    "    lengths = []\n",
    "    tk0 = tqdm(train_df['text'].fillna(\"\").values, total=len(train_df))\n",
    "    \n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "        \n",
    "    model_config.max_len = max(lengths) + 2 # cls & sep\n",
    "    LOGGER.info(f\"max_len: {config.max_len}\")\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    \n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[config.target_cols].values\n",
    "    \n",
    "    train_dataset = TrainDataset(model_config, train_folds)\n",
    "    valid_dataset = TrainDataset(model_config, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=model_config.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=model_config.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=model_config.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=model_config.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(model_config, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=model_config.encoder_lr, \n",
    "                                                decoder_lr=model_config.decoder_lr,\n",
    "                                                weight_decay=model_config.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=model_config.encoder_lr, eps=model_config.eps, betas=model_config.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(model_config, optimizer, num_train_steps):\n",
    "        if model_config.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=model_config.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif model_config.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=model_config.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=model_config.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / model_config.batch_size * model_config.epochs)\n",
    "    scheduler = get_scheduler(config, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.SmoothL1Loss(reduction='mean') # RMSELoss(reduction=\"mean\")\n",
    "    \n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(model_config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        # scoring\n",
    "        score, scores = get_score(valid_labels, predictions)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
    "        \n",
    "        if best_score > score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                         os.path.join(dir_output, f\"{model_config.model.replace('/', '-')}_fold{fold}_best.pth\"))\n",
    "\n",
    "    predictions = torch.load(os.path.join(dir_output, f\"{model_config.model.replace('/', '-')}_fold{fold}_best.pth\"), \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in model_config.target_cols]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbdd88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T11:54:39.601289Z",
     "iopub.status.busy": "2023-08-19T11:54:39.600525Z",
     "iopub.status.idle": "2023-08-19T12:46:38.891312Z",
     "shell.execute_reply": "2023-08-19T12:46:38.889931Z"
    },
    "papermill": {
     "duration": 3119.370568,
     "end_time": "2023-08-19T12:46:38.964201",
     "exception": true,
     "start_time": "2023-08-19T11:54:39.593633",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 Experiment: base-deberta\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f7c2913a1c470fb2858ffc8d04c436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6104befa4c44ff835cda6661de4d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2273e87a76e4f73b60ba498ec4f8604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d6f9856be0461c8ffec9e45188d920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 512\n",
      "========== fold: 0 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d097f81bd61340b6839a57b96fb38d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/671] Elapsed 0m 2s (remain 25m 26s) Loss: 0.9646(0.9646) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/671] Elapsed 0m 7s (remain 3m 37s) Loss: 0.7998(0.5248) Grad: 28477.8379  LR: 0.00002000  \n",
      "Epoch: [1][40/671] Elapsed 0m 11s (remain 3m 1s) Loss: 0.2424(0.4071) Grad: 26165.3359  LR: 0.00001999  \n",
      "Epoch: [1][60/671] Elapsed 0m 16s (remain 2m 45s) Loss: 0.2788(0.3422) Grad: 30115.7930  LR: 0.00001997  \n",
      "Epoch: [1][80/671] Elapsed 0m 22s (remain 2m 43s) Loss: 0.2076(0.3032) Grad: 30670.9824  LR: 0.00001996  \n",
      "Epoch: [1][100/671] Elapsed 0m 27s (remain 2m 36s) Loss: 0.1905(0.2720) Grad: 30739.7461  LR: 0.00001993  \n",
      "Epoch: [1][120/671] Elapsed 0m 32s (remain 2m 27s) Loss: 0.1273(0.2548) Grad: 12413.3271  LR: 0.00001990  \n",
      "Epoch: [1][140/671] Elapsed 0m 36s (remain 2m 18s) Loss: 0.2331(0.2422) Grad: 41199.8398  LR: 0.00001986  \n",
      "Epoch: [1][160/671] Elapsed 0m 41s (remain 2m 12s) Loss: 0.0710(0.2325) Grad: 9542.8809  LR: 0.00001982  \n",
      "Epoch: [1][180/671] Elapsed 0m 46s (remain 2m 6s) Loss: 0.1922(0.2267) Grad: 21005.0879  LR: 0.00001978  \n",
      "Epoch: [1][200/671] Elapsed 0m 51s (remain 2m 0s) Loss: 0.1393(0.2207) Grad: 10820.8799  LR: 0.00001973  \n",
      "Epoch: [1][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0640(0.2165) Grad: 6963.4834  LR: 0.00001967  \n",
      "Epoch: [1][240/671] Elapsed 1m 2s (remain 1m 50s) Loss: 0.2694(0.2132) Grad: 47775.1758  LR: 0.00001961  \n",
      "Epoch: [1][260/671] Elapsed 1m 7s (remain 1m 46s) Loss: 0.1245(0.2103) Grad: 14567.3418  LR: 0.00001954  \n",
      "Epoch: [1][280/671] Elapsed 1m 13s (remain 1m 41s) Loss: 0.0740(0.2060) Grad: 20290.7188  LR: 0.00001947  \n",
      "Epoch: [1][300/671] Elapsed 1m 18s (remain 1m 36s) Loss: 0.1025(0.2060) Grad: 11362.3926  LR: 0.00001939  \n",
      "Epoch: [1][320/671] Elapsed 1m 23s (remain 1m 31s) Loss: 0.1503(0.2021) Grad: 18533.0957  LR: 0.00001930  \n",
      "Epoch: [1][340/671] Elapsed 1m 28s (remain 1m 25s) Loss: 0.1382(0.1981) Grad: 8638.5137  LR: 0.00001922  \n",
      "Epoch: [1][360/671] Elapsed 1m 33s (remain 1m 20s) Loss: 0.0373(0.1957) Grad: 10834.9121  LR: 0.00001912  \n",
      "Epoch: [1][380/671] Elapsed 1m 38s (remain 1m 15s) Loss: 0.2179(0.1936) Grad: 15648.9375  LR: 0.00001902  \n",
      "Epoch: [1][400/671] Elapsed 1m 43s (remain 1m 9s) Loss: 0.3197(0.1920) Grad: 27618.0547  LR: 0.00001892  \n",
      "Epoch: [1][420/671] Elapsed 1m 48s (remain 1m 4s) Loss: 0.1669(0.1889) Grad: 19071.8750  LR: 0.00001881  \n",
      "Epoch: [1][440/671] Elapsed 1m 53s (remain 0m 59s) Loss: 0.1121(0.1870) Grad: 13914.5225  LR: 0.00001870  \n",
      "Epoch: [1][460/671] Elapsed 1m 58s (remain 0m 53s) Loss: 0.1236(0.1837) Grad: 17826.0859  LR: 0.00001858  \n",
      "Epoch: [1][480/671] Elapsed 2m 2s (remain 0m 48s) Loss: 0.0641(0.1814) Grad: 16624.5352  LR: 0.00001846  \n",
      "Epoch: [1][500/671] Elapsed 2m 7s (remain 0m 43s) Loss: 0.1486(0.1797) Grad: 31806.4766  LR: 0.00001833  \n",
      "Epoch: [1][520/671] Elapsed 2m 13s (remain 0m 38s) Loss: 0.0987(0.1777) Grad: 15573.3438  LR: 0.00001820  \n",
      "Epoch: [1][540/671] Elapsed 2m 18s (remain 0m 33s) Loss: 0.1102(0.1774) Grad: 20519.6543  LR: 0.00001807  \n",
      "Epoch: [1][560/671] Elapsed 2m 24s (remain 0m 28s) Loss: 0.1202(0.1766) Grad: 22241.5273  LR: 0.00001792  \n",
      "Epoch: [1][580/671] Elapsed 2m 29s (remain 0m 23s) Loss: 0.0986(0.1751) Grad: 11303.8770  LR: 0.00001778  \n",
      "Epoch: [1][600/671] Elapsed 2m 35s (remain 0m 18s) Loss: 0.1085(0.1735) Grad: 13019.7559  LR: 0.00001763  \n",
      "Epoch: [1][620/671] Elapsed 2m 39s (remain 0m 12s) Loss: 0.0887(0.1715) Grad: 19307.7598  LR: 0.00001748  \n",
      "Epoch: [1][640/671] Elapsed 2m 44s (remain 0m 7s) Loss: 0.1588(0.1702) Grad: 32689.7891  LR: 0.00001732  \n",
      "Epoch: [1][660/671] Elapsed 2m 49s (remain 0m 2s) Loss: 0.1089(0.1687) Grad: 18984.3008  LR: 0.00001716  \n",
      "Epoch: [1][670/671] Elapsed 2m 51s (remain 0m 0s) Loss: 0.0645(0.1678) Grad: 5024.4419  LR: 0.00001708  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 50s) Loss: 0.1178(0.1178) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 16s) Loss: 0.1356(0.1258) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 12s) Loss: 0.1006(0.1217) \n",
      "EVAL: [60/112] Elapsed 0m 10s (remain 0m 8s) Loss: 0.0899(0.1208) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.1109(0.1165) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.2339(0.1196) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.1678  avg_val_loss: 0.1190  time: 192s\n",
      "Epoch 1 - Score: 0.4970  Scores: [0.43478886423301266, 0.5592748602553492]\n",
      "Epoch 1 - Save Best Score: 0.4970 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0865(0.1190) \n",
      "Epoch: [2][0/671] Elapsed 0m 0s (remain 5m 25s) Loss: 0.0417(0.0417) Grad: inf  LR: 0.00001707  \n",
      "Epoch: [2][20/671] Elapsed 0m 5s (remain 2m 53s) Loss: 0.0600(0.0982) Grad: 29518.3359  LR: 0.00001690  \n",
      "Epoch: [2][40/671] Elapsed 0m 10s (remain 2m 38s) Loss: 0.0370(0.0898) Grad: 19615.6055  LR: 0.00001673  \n",
      "Epoch: [2][60/671] Elapsed 0m 14s (remain 2m 29s) Loss: 0.0644(0.0868) Grad: 31380.6309  LR: 0.00001656  \n",
      "Epoch: [2][80/671] Elapsed 0m 19s (remain 2m 25s) Loss: 0.1407(0.0883) Grad: 55148.3203  LR: 0.00001638  \n",
      "Epoch: [2][100/671] Elapsed 0m 25s (remain 2m 21s) Loss: 0.1262(0.0878) Grad: 31479.7734  LR: 0.00001620  \n",
      "Epoch: [2][120/671] Elapsed 0m 30s (remain 2m 17s) Loss: 0.0645(0.0897) Grad: 22207.4219  LR: 0.00001601  \n",
      "Epoch: [2][140/671] Elapsed 0m 35s (remain 2m 14s) Loss: 0.2540(0.0917) Grad: 45000.5352  LR: 0.00001582  \n",
      "Epoch: [2][160/671] Elapsed 0m 41s (remain 2m 11s) Loss: 0.0923(0.0922) Grad: 37021.3594  LR: 0.00001563  \n",
      "Epoch: [2][180/671] Elapsed 0m 46s (remain 2m 5s) Loss: 0.0533(0.0913) Grad: 9786.1250  LR: 0.00001544  \n",
      "Epoch: [2][200/671] Elapsed 0m 51s (remain 2m 0s) Loss: 0.1024(0.0912) Grad: 37869.4219  LR: 0.00001524  \n",
      "Epoch: [2][220/671] Elapsed 0m 55s (remain 1m 53s) Loss: 0.1072(0.0901) Grad: 29769.6328  LR: 0.00001504  \n",
      "Epoch: [2][240/671] Elapsed 1m 1s (remain 1m 48s) Loss: 0.0670(0.0900) Grad: 17792.4062  LR: 0.00001483  \n",
      "Epoch: [2][260/671] Elapsed 1m 5s (remain 1m 43s) Loss: 0.0597(0.0895) Grad: 18806.0664  LR: 0.00001463  \n",
      "Epoch: [2][280/671] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0922(0.0904) Grad: 26921.3340  LR: 0.00001442  \n",
      "Epoch: [2][300/671] Elapsed 1m 16s (remain 1m 33s) Loss: 0.1577(0.0912) Grad: 47973.4844  LR: 0.00001421  \n",
      "Epoch: [2][320/671] Elapsed 1m 22s (remain 1m 29s) Loss: 0.1663(0.0919) Grad: 34202.6250  LR: 0.00001399  \n",
      "Epoch: [2][340/671] Elapsed 1m 27s (remain 1m 24s) Loss: 0.1278(0.0920) Grad: 28357.2441  LR: 0.00001378  \n",
      "Epoch: [2][360/671] Elapsed 1m 32s (remain 1m 19s) Loss: 0.1205(0.0913) Grad: 28081.3340  LR: 0.00001356  \n",
      "Epoch: [2][380/671] Elapsed 1m 37s (remain 1m 14s) Loss: 0.1513(0.0906) Grad: 17531.3105  LR: 0.00001334  \n",
      "Epoch: [2][400/671] Elapsed 1m 42s (remain 1m 9s) Loss: 0.0949(0.0905) Grad: 28640.1973  LR: 0.00001312  \n",
      "Epoch: [2][420/671] Elapsed 1m 47s (remain 1m 3s) Loss: 0.0764(0.0906) Grad: 22062.6738  LR: 0.00001290  \n",
      "Epoch: [2][440/671] Elapsed 1m 52s (remain 0m 58s) Loss: 0.0676(0.0903) Grad: 35646.5742  LR: 0.00001267  \n",
      "Epoch: [2][460/671] Elapsed 1m 57s (remain 0m 53s) Loss: 0.0794(0.0903) Grad: 40163.3203  LR: 0.00001245  \n",
      "Epoch: [2][480/671] Elapsed 2m 2s (remain 0m 48s) Loss: 0.0539(0.0897) Grad: 22992.5059  LR: 0.00001222  \n",
      "Epoch: [2][500/671] Elapsed 2m 7s (remain 0m 43s) Loss: 0.0442(0.0897) Grad: 10804.5957  LR: 0.00001199  \n",
      "Epoch: [2][520/671] Elapsed 2m 12s (remain 0m 38s) Loss: 0.0680(0.0895) Grad: 26566.2207  LR: 0.00001176  \n",
      "Epoch: [2][540/671] Elapsed 2m 16s (remain 0m 32s) Loss: 0.1016(0.0894) Grad: 16154.1855  LR: 0.00001153  \n",
      "Epoch: [2][560/671] Elapsed 2m 22s (remain 0m 27s) Loss: 0.0626(0.0896) Grad: 28616.6582  LR: 0.00001130  \n",
      "Epoch: [2][580/671] Elapsed 2m 27s (remain 0m 22s) Loss: 0.1580(0.0897) Grad: 48255.8125  LR: 0.00001107  \n",
      "Epoch: [2][600/671] Elapsed 2m 32s (remain 0m 17s) Loss: 0.1058(0.0895) Grad: 33650.9961  LR: 0.00001083  \n",
      "Epoch: [2][620/671] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0722(0.0893) Grad: 29639.2305  LR: 0.00001060  \n",
      "Epoch: [2][640/671] Elapsed 2m 43s (remain 0m 7s) Loss: 0.0821(0.0892) Grad: 22976.7617  LR: 0.00001037  \n",
      "Epoch: [2][660/671] Elapsed 2m 48s (remain 0m 2s) Loss: 0.0901(0.0890) Grad: 27399.9297  LR: 0.00001013  \n",
      "Epoch: [2][670/671] Elapsed 2m 50s (remain 0m 0s) Loss: 0.1327(0.0892) Grad: 45962.5234  LR: 0.00001002  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1335(0.1335) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 15s) Loss: 0.1296(0.1202) \n",
      "EVAL: [40/112] Elapsed 0m 6s (remain 0m 12s) Loss: 0.1038(0.1157) \n",
      "EVAL: [60/112] Elapsed 0m 10s (remain 0m 8s) Loss: 0.0860(0.1146) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.1090(0.1120) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.2392(0.1140) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0892  avg_val_loss: 0.1140  time: 190s\n",
      "Epoch 2 - Score: 0.4824  Scores: [0.41748048304465085, 0.547367119767985]\n",
      "Epoch 2 - Save Best Score: 0.4824 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0639(0.1140) \n",
      "Epoch: [3][0/671] Elapsed 0m 0s (remain 7m 57s) Loss: 0.1636(0.1636) Grad: inf  LR: 0.00001001  \n",
      "Epoch: [3][20/671] Elapsed 0m 5s (remain 2m 55s) Loss: 0.0454(0.0645) Grad: 54203.9492  LR: 0.00000977  \n",
      "Epoch: [3][40/671] Elapsed 0m 9s (remain 2m 32s) Loss: 0.0349(0.0580) Grad: 25290.9336  LR: 0.00000954  \n",
      "Epoch: [3][60/671] Elapsed 0m 15s (remain 2m 35s) Loss: 0.0734(0.0610) Grad: 39819.9531  LR: 0.00000930  \n",
      "Epoch: [3][80/671] Elapsed 0m 20s (remain 2m 27s) Loss: 0.0419(0.0610) Grad: 53522.3164  LR: 0.00000907  \n",
      "Epoch: [3][100/671] Elapsed 0m 25s (remain 2m 23s) Loss: 0.0460(0.0617) Grad: 42439.7500  LR: 0.00000884  \n",
      "Epoch: [3][120/671] Elapsed 0m 30s (remain 2m 17s) Loss: 0.1109(0.0632) Grad: 56431.8945  LR: 0.00000861  \n",
      "Epoch: [3][140/671] Elapsed 0m 35s (remain 2m 12s) Loss: 0.0758(0.0654) Grad: 49448.9297  LR: 0.00000838  \n",
      "Epoch: [3][160/671] Elapsed 0m 40s (remain 2m 7s) Loss: 0.0247(0.0645) Grad: 20055.3418  LR: 0.00000815  \n",
      "Epoch: [3][180/671] Elapsed 0m 44s (remain 2m 1s) Loss: 0.0583(0.0640) Grad: 49817.6680  LR: 0.00000792  \n",
      "Epoch: [3][200/671] Elapsed 0m 49s (remain 1m 56s) Loss: 0.0391(0.0653) Grad: 36228.2617  LR: 0.00000769  \n",
      "Epoch: [3][220/671] Elapsed 0m 54s (remain 1m 50s) Loss: 0.0464(0.0647) Grad: 30416.0078  LR: 0.00000746  \n",
      "Epoch: [3][240/671] Elapsed 0m 59s (remain 1m 46s) Loss: 0.0701(0.0639) Grad: 59486.2617  LR: 0.00000724  \n",
      "Epoch: [3][260/671] Elapsed 1m 4s (remain 1m 41s) Loss: 0.0676(0.0637) Grad: 41571.5391  LR: 0.00000701  \n",
      "Epoch: [3][280/671] Elapsed 1m 9s (remain 1m 37s) Loss: 0.0422(0.0634) Grad: 49772.2344  LR: 0.00000679  \n",
      "Epoch: [3][300/671] Elapsed 1m 15s (remain 1m 32s) Loss: 0.0480(0.0627) Grad: 62706.2617  LR: 0.00000657  \n",
      "Epoch: [3][320/671] Elapsed 1m 19s (remain 1m 27s) Loss: 0.0278(0.0621) Grad: 35489.1211  LR: 0.00000635  \n",
      "Epoch: [3][340/671] Elapsed 1m 24s (remain 1m 22s) Loss: 0.0686(0.0621) Grad: 76853.2344  LR: 0.00000613  \n",
      "Epoch: [3][360/671] Elapsed 1m 30s (remain 1m 17s) Loss: 0.0418(0.0622) Grad: 42003.7148  LR: 0.00000592  \n",
      "Epoch: [3][380/671] Elapsed 1m 35s (remain 1m 12s) Loss: 0.0720(0.0622) Grad: 49477.5273  LR: 0.00000571  \n",
      "Epoch: [3][400/671] Elapsed 1m 40s (remain 1m 7s) Loss: 0.1123(0.0619) Grad: 51864.5469  LR: 0.00000550  \n",
      "Epoch: [3][420/671] Elapsed 1m 46s (remain 1m 3s) Loss: 0.0665(0.0618) Grad: 33560.7695  LR: 0.00000529  \n",
      "Epoch: [3][440/671] Elapsed 1m 51s (remain 0m 58s) Loss: 0.0618(0.0613) Grad: 71893.3047  LR: 0.00000508  \n",
      "Epoch: [3][460/671] Elapsed 1m 55s (remain 0m 52s) Loss: 0.0654(0.0613) Grad: 54304.9258  LR: 0.00000488  \n",
      "Epoch: [3][480/671] Elapsed 2m 2s (remain 0m 48s) Loss: 0.0332(0.0610) Grad: 32286.7969  LR: 0.00000468  \n",
      "Epoch: [3][500/671] Elapsed 2m 6s (remain 0m 43s) Loss: 0.0233(0.0605) Grad: 20531.0449  LR: 0.00000449  \n",
      "Epoch: [3][520/671] Elapsed 2m 11s (remain 0m 37s) Loss: 0.0986(0.0604) Grad: 64147.1211  LR: 0.00000429  \n",
      "Epoch: [3][540/671] Elapsed 2m 17s (remain 0m 32s) Loss: 0.0515(0.0602) Grad: 53590.9258  LR: 0.00000410  \n",
      "Epoch: [3][560/671] Elapsed 2m 22s (remain 0m 27s) Loss: 0.0752(0.0600) Grad: 79880.5703  LR: 0.00000392  \n",
      "Epoch: [3][580/671] Elapsed 2m 27s (remain 0m 22s) Loss: 0.0489(0.0598) Grad: 80130.7578  LR: 0.00000373  \n",
      "Epoch: [3][600/671] Elapsed 2m 32s (remain 0m 17s) Loss: 0.0635(0.0595) Grad: 35642.5000  LR: 0.00000355  \n",
      "Epoch: [3][620/671] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0740(0.0594) Grad: 58804.3789  LR: 0.00000337  \n",
      "Epoch: [3][640/671] Elapsed 2m 42s (remain 0m 7s) Loss: 0.0367(0.0592) Grad: 21492.7227  LR: 0.00000320  \n",
      "Epoch: [3][660/671] Elapsed 2m 46s (remain 0m 2s) Loss: 0.0577(0.0594) Grad: 52919.6328  LR: 0.00000303  \n",
      "Epoch: [3][670/671] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0800(0.0595) Grad: 108816.1562  LR: 0.00000295  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 50s) Loss: 0.1049(0.1049) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 16s) Loss: 0.1238(0.1148) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 12s) Loss: 0.0932(0.1089) \n",
      "EVAL: [60/112] Elapsed 0m 10s (remain 0m 8s) Loss: 0.0727(0.1069) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.1122(0.1037) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.2375(0.1057) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0595  avg_val_loss: 0.1057  time: 189s\n",
      "Epoch 3 - Score: 0.4624  Scores: [0.39352794482055337, 0.5313026693500256]\n",
      "Epoch 3 - Save Best Score: 0.4624 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0696(0.1057) \n",
      "Epoch: [4][0/671] Elapsed 0m 0s (remain 4m 34s) Loss: 0.0252(0.0252) Grad: 142171.5938  LR: 0.00000294  \n",
      "Epoch: [4][20/671] Elapsed 0m 5s (remain 2m 39s) Loss: 0.0446(0.0446) Grad: 39119.7227  LR: 0.00000278  \n",
      "Epoch: [4][40/671] Elapsed 0m 9s (remain 2m 28s) Loss: 0.0436(0.0454) Grad: 42712.3711  LR: 0.00000262  \n",
      "Epoch: [4][60/671] Elapsed 0m 14s (remain 2m 26s) Loss: 0.0421(0.0442) Grad: 54246.7695  LR: 0.00000246  \n",
      "Epoch: [4][80/671] Elapsed 0m 20s (remain 2m 29s) Loss: 0.0558(0.0476) Grad: 40351.3789  LR: 0.00000231  \n",
      "Epoch: [4][100/671] Elapsed 0m 26s (remain 2m 27s) Loss: 0.0428(0.0486) Grad: 55406.3008  LR: 0.00000216  \n",
      "Epoch: [4][120/671] Elapsed 0m 30s (remain 2m 20s) Loss: 0.0743(0.0481) Grad: 56595.5625  LR: 0.00000202  \n",
      "Epoch: [4][140/671] Elapsed 0m 36s (remain 2m 16s) Loss: 0.0465(0.0480) Grad: 31243.8672  LR: 0.00000188  \n",
      "Epoch: [4][160/671] Elapsed 0m 40s (remain 2m 8s) Loss: 0.0371(0.0480) Grad: 39197.1797  LR: 0.00000175  \n",
      "Epoch: [4][180/671] Elapsed 0m 45s (remain 2m 3s) Loss: 0.0295(0.0484) Grad: 22394.7090  LR: 0.00000162  \n",
      "Epoch: [4][200/671] Elapsed 0m 51s (remain 2m 0s) Loss: 0.0928(0.0482) Grad: 64348.0547  LR: 0.00000149  \n",
      "Epoch: [4][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0919(0.0483) Grad: 88315.8672  LR: 0.00000137  \n",
      "Epoch: [4][240/671] Elapsed 1m 1s (remain 1m 49s) Loss: 0.0201(0.0477) Grad: 38520.0508  LR: 0.00000125  \n",
      "Epoch: [4][260/671] Elapsed 1m 6s (remain 1m 43s) Loss: 0.0442(0.0476) Grad: 27530.0723  LR: 0.00000114  \n",
      "Epoch: [4][280/671] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0364(0.0470) Grad: 34934.9844  LR: 0.00000104  \n",
      "Epoch: [4][300/671] Elapsed 1m 16s (remain 1m 33s) Loss: 0.0322(0.0466) Grad: 40087.7383  LR: 0.00000094  \n",
      "Epoch: [4][320/671] Elapsed 1m 21s (remain 1m 28s) Loss: 0.0321(0.0465) Grad: 27829.7480  LR: 0.00000084  \n",
      "Epoch: [4][340/671] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0293(0.0466) Grad: 27171.9746  LR: 0.00000075  \n",
      "Epoch: [4][360/671] Elapsed 1m 33s (remain 1m 20s) Loss: 0.0717(0.0469) Grad: 41344.6211  LR: 0.00000066  \n",
      "Epoch: [4][380/671] Elapsed 1m 38s (remain 1m 15s) Loss: 0.0552(0.0469) Grad: 48563.0430  LR: 0.00000058  \n",
      "Epoch: [4][400/671] Elapsed 1m 43s (remain 1m 9s) Loss: 0.0574(0.0471) Grad: 50568.0664  LR: 0.00000051  \n",
      "Epoch: [4][420/671] Elapsed 1m 48s (remain 1m 4s) Loss: 0.0165(0.0471) Grad: 30724.4219  LR: 0.00000043  \n",
      "Epoch: [4][440/671] Elapsed 1m 52s (remain 0m 58s) Loss: 0.0212(0.0469) Grad: 23668.0605  LR: 0.00000037  \n",
      "Epoch: [4][460/671] Elapsed 1m 58s (remain 0m 54s) Loss: 0.0261(0.0471) Grad: 27328.4531  LR: 0.00000031  \n",
      "Epoch: [4][480/671] Elapsed 2m 3s (remain 0m 48s) Loss: 0.0622(0.0468) Grad: 45920.2930  LR: 0.00000025  \n",
      "Epoch: [4][500/671] Elapsed 2m 8s (remain 0m 43s) Loss: 0.0418(0.0470) Grad: 47885.0234  LR: 0.00000020  \n",
      "Epoch: [4][520/671] Elapsed 2m 13s (remain 0m 38s) Loss: 0.0345(0.0467) Grad: 34667.6211  LR: 0.00000016  \n",
      "Epoch: [4][540/671] Elapsed 2m 18s (remain 0m 33s) Loss: 0.0396(0.0467) Grad: 32973.5469  LR: 0.00000012  \n",
      "Epoch: [4][560/671] Elapsed 2m 22s (remain 0m 27s) Loss: 0.1065(0.0466) Grad: 109754.9844  LR: 0.00000009  \n",
      "Epoch: [4][580/671] Elapsed 2m 27s (remain 0m 22s) Loss: 0.0315(0.0465) Grad: 32346.8340  LR: 0.00000006  \n",
      "Epoch: [4][600/671] Elapsed 2m 32s (remain 0m 17s) Loss: 0.0288(0.0466) Grad: 20565.1055  LR: 0.00000004  \n",
      "Epoch: [4][620/671] Elapsed 2m 37s (remain 0m 12s) Loss: 0.0507(0.0466) Grad: 32538.1973  LR: 0.00000002  \n",
      "Epoch: [4][640/671] Elapsed 2m 42s (remain 0m 7s) Loss: 0.0531(0.0466) Grad: 27162.3789  LR: 0.00000001  \n",
      "Epoch: [4][660/671] Elapsed 2m 47s (remain 0m 2s) Loss: 0.0672(0.0467) Grad: 43342.9609  LR: 0.00000000  \n",
      "Epoch: [4][670/671] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0327(0.0466) Grad: 51661.6797  LR: 0.00000000  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 46s) Loss: 0.1039(0.1039) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 15s) Loss: 0.1287(0.1149) \n",
      "EVAL: [40/112] Elapsed 0m 6s (remain 0m 12s) Loss: 0.0902(0.1091) \n",
      "EVAL: [60/112] Elapsed 0m 10s (remain 0m 8s) Loss: 0.0790(0.1067) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.1001(0.1042) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.2580(0.1062) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0466  avg_val_loss: 0.1059  time: 189s\n",
      "Epoch 4 - Score: 0.4623  Scores: [0.3907715855277538, 0.5337474935285607]\n",
      "Epoch 4 - Save Best Score: 0.4623 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0766(0.1059) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.4623  Scores: [0.3907715855277538, 0.5337474935285607]\n",
      "========== CV ==========\n",
      "Score: 0.4623  Scores: [0.3907715855277538, 0.5337474935285607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 Experiment: base-deberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efa6544caf84c12bae5ce91cd3e05df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 512\n",
      "========== fold: 1 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/671] Elapsed 0m 0s (remain 4m 16s) Loss: 0.3736(0.3736) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/671] Elapsed 0m 5s (remain 2m 54s) Loss: 0.2846(0.3196) Grad: 105256.9062  LR: 0.00002000  \n",
      "Epoch: [1][40/671] Elapsed 0m 10s (remain 2m 44s) Loss: 0.2152(0.2704) Grad: 20439.1914  LR: 0.00001999  \n",
      "Epoch: [1][60/671] Elapsed 0m 16s (remain 2m 42s) Loss: 0.2072(0.2503) Grad: 33971.5664  LR: 0.00001997  \n",
      "Epoch: [1][80/671] Elapsed 0m 21s (remain 2m 33s) Loss: 0.2527(0.2445) Grad: 33160.0430  LR: 0.00001996  \n",
      "Epoch: [1][100/671] Elapsed 0m 26s (remain 2m 27s) Loss: 0.0958(0.2258) Grad: 60984.6602  LR: 0.00001993  \n",
      "Epoch: [1][120/671] Elapsed 0m 30s (remain 2m 18s) Loss: 0.3466(0.2235) Grad: 105138.1719  LR: 0.00001990  \n",
      "Epoch: [1][140/671] Elapsed 0m 35s (remain 2m 13s) Loss: 0.0517(0.2140) Grad: 30091.6133  LR: 0.00001986  \n",
      "Epoch: [1][160/671] Elapsed 0m 40s (remain 2m 7s) Loss: 0.1912(0.2071) Grad: 108952.7812  LR: 0.00001982  \n",
      "Epoch: [1][180/671] Elapsed 0m 44s (remain 2m 1s) Loss: 0.2000(0.2014) Grad: 46297.7109  LR: 0.00001978  \n",
      "Epoch: [1][200/671] Elapsed 0m 49s (remain 1m 56s) Loss: 0.1000(0.1977) Grad: 44348.1914  LR: 0.00001973  \n",
      "Epoch: [1][220/671] Elapsed 0m 54s (remain 1m 50s) Loss: 0.1372(0.1925) Grad: 28875.7188  LR: 0.00001967  \n",
      "Epoch: [1][240/671] Elapsed 0m 59s (remain 1m 45s) Loss: 0.1613(0.1906) Grad: 38587.2852  LR: 0.00001961  \n",
      "Epoch: [1][260/671] Elapsed 1m 3s (remain 1m 40s) Loss: 0.0496(0.1863) Grad: 31004.2383  LR: 0.00001954  \n",
      "Epoch: [1][280/671] Elapsed 1m 8s (remain 1m 34s) Loss: 0.1713(0.1846) Grad: 62742.7852  LR: 0.00001947  \n",
      "Epoch: [1][300/671] Elapsed 1m 13s (remain 1m 29s) Loss: 0.2500(0.1810) Grad: 39368.1016  LR: 0.00001939  \n",
      "Epoch: [1][320/671] Elapsed 1m 18s (remain 1m 25s) Loss: 0.1201(0.1813) Grad: 36907.2266  LR: 0.00001930  \n",
      "Epoch: [1][340/671] Elapsed 1m 23s (remain 1m 20s) Loss: 0.1284(0.1780) Grad: 49584.6328  LR: 0.00001922  \n",
      "Epoch: [1][360/671] Elapsed 1m 28s (remain 1m 16s) Loss: 0.1159(0.1748) Grad: 30704.7656  LR: 0.00001912  \n",
      "Epoch: [1][380/671] Elapsed 1m 33s (remain 1m 11s) Loss: 0.2507(0.1729) Grad: 99646.9531  LR: 0.00001902  \n",
      "Epoch: [1][400/671] Elapsed 1m 38s (remain 1m 6s) Loss: 0.0844(0.1718) Grad: 24827.3477  LR: 0.00001892  \n",
      "Epoch: [1][420/671] Elapsed 1m 44s (remain 1m 1s) Loss: 0.4025(0.1698) Grad: 61531.6328  LR: 0.00001881  \n",
      "Epoch: [1][440/671] Elapsed 1m 49s (remain 0m 57s) Loss: 0.1840(0.1703) Grad: 50251.1914  LR: 0.00001870  \n",
      "Epoch: [1][460/671] Elapsed 1m 54s (remain 0m 52s) Loss: 0.2026(0.1692) Grad: 50323.9102  LR: 0.00001858  \n",
      "Epoch: [1][480/671] Elapsed 1m 59s (remain 0m 47s) Loss: 0.1455(0.1689) Grad: 33300.3633  LR: 0.00001846  \n",
      "Epoch: [1][500/671] Elapsed 2m 4s (remain 0m 42s) Loss: 0.1173(0.1667) Grad: 52372.3516  LR: 0.00001833  \n",
      "Epoch: [1][520/671] Elapsed 2m 9s (remain 0m 37s) Loss: 0.1417(0.1657) Grad: 67723.3516  LR: 0.00001820  \n",
      "Epoch: [1][540/671] Elapsed 2m 14s (remain 0m 32s) Loss: 0.1547(0.1645) Grad: 77784.0625  LR: 0.00001807  \n",
      "Epoch: [1][560/671] Elapsed 2m 20s (remain 0m 27s) Loss: 0.1073(0.1634) Grad: 35359.9375  LR: 0.00001792  \n",
      "Epoch: [1][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.1018(0.1621) Grad: 16584.2656  LR: 0.00001778  \n",
      "Epoch: [1][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.1093(0.1617) Grad: 19304.4219  LR: 0.00001763  \n",
      "Epoch: [1][620/671] Elapsed 2m 36s (remain 0m 12s) Loss: 0.1329(0.1601) Grad: 41998.6875  LR: 0.00001748  \n",
      "Epoch: [1][640/671] Elapsed 2m 40s (remain 0m 7s) Loss: 0.0959(0.1591) Grad: 41872.5820  LR: 0.00001732  \n",
      "Epoch: [1][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.1551(0.1581) Grad: 47656.5430  LR: 0.00001716  \n",
      "Epoch: [1][670/671] Elapsed 2m 48s (remain 0m 0s) Loss: 0.0917(0.1575) Grad: 35737.1641  LR: 0.00001708  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 52s) Loss: 0.1383(0.1383) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 17s) Loss: 0.1143(0.1151) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.0999(0.1214) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1244(0.1202) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0854(0.1226) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.1351(0.1248) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.1575  avg_val_loss: 0.1238  time: 188s\n",
      "Epoch 1 - Score: 0.5012  Scores: [0.4312315981840947, 0.571094900589673]\n",
      "Epoch 1 - Save Best Score: 0.5012 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0889(0.1238) \n",
      "Epoch: [2][0/671] Elapsed 0m 0s (remain 6m 49s) Loss: 0.1641(0.1641) Grad: inf  LR: 0.00001707  \n",
      "Epoch: [2][20/671] Elapsed 0m 5s (remain 2m 56s) Loss: 0.0894(0.1058) Grad: 103648.1406  LR: 0.00001690  \n",
      "Epoch: [2][40/671] Elapsed 0m 12s (remain 3m 7s) Loss: 0.0573(0.0941) Grad: 44718.2695  LR: 0.00001673  \n",
      "Epoch: [2][60/671] Elapsed 0m 17s (remain 2m 57s) Loss: 0.1022(0.0916) Grad: 51567.9297  LR: 0.00001656  \n",
      "Epoch: [2][80/671] Elapsed 0m 22s (remain 2m 42s) Loss: 0.0586(0.0932) Grad: 46527.0547  LR: 0.00001638  \n",
      "Epoch: [2][100/671] Elapsed 0m 27s (remain 2m 33s) Loss: 0.0422(0.0920) Grad: 23642.1855  LR: 0.00001620  \n",
      "Epoch: [2][120/671] Elapsed 0m 31s (remain 2m 24s) Loss: 0.1009(0.0921) Grad: 33985.0742  LR: 0.00001601  \n",
      "Epoch: [2][140/671] Elapsed 0m 36s (remain 2m 16s) Loss: 0.0561(0.0930) Grad: 16955.5859  LR: 0.00001582  \n",
      "Epoch: [2][160/671] Elapsed 0m 41s (remain 2m 11s) Loss: 0.0644(0.0922) Grad: 15149.9863  LR: 0.00001563  \n",
      "Epoch: [2][180/671] Elapsed 0m 46s (remain 2m 5s) Loss: 0.0405(0.0923) Grad: 32666.4590  LR: 0.00001544  \n",
      "Epoch: [2][200/671] Elapsed 0m 51s (remain 1m 59s) Loss: 0.1037(0.0942) Grad: 35997.8984  LR: 0.00001524  \n",
      "Epoch: [2][220/671] Elapsed 0m 56s (remain 1m 54s) Loss: 0.0671(0.0945) Grad: 20781.6758  LR: 0.00001504  \n",
      "Epoch: [2][240/671] Elapsed 1m 1s (remain 1m 48s) Loss: 0.2026(0.0945) Grad: 43424.9531  LR: 0.00001483  \n",
      "Epoch: [2][260/671] Elapsed 1m 5s (remain 1m 43s) Loss: 0.0682(0.0950) Grad: 39845.6289  LR: 0.00001463  \n",
      "Epoch: [2][280/671] Elapsed 1m 10s (remain 1m 38s) Loss: 0.0601(0.0955) Grad: 24170.2129  LR: 0.00001442  \n",
      "Epoch: [2][300/671] Elapsed 1m 16s (remain 1m 33s) Loss: 0.1798(0.0964) Grad: 40979.1289  LR: 0.00001421  \n",
      "Epoch: [2][320/671] Elapsed 1m 21s (remain 1m 28s) Loss: 0.0529(0.0967) Grad: 56799.5078  LR: 0.00001399  \n",
      "Epoch: [2][340/671] Elapsed 1m 26s (remain 1m 23s) Loss: 0.1232(0.0959) Grad: 39082.9531  LR: 0.00001378  \n",
      "Epoch: [2][360/671] Elapsed 1m 31s (remain 1m 18s) Loss: 0.1108(0.0962) Grad: 39475.4492  LR: 0.00001356  \n",
      "Epoch: [2][380/671] Elapsed 1m 35s (remain 1m 12s) Loss: 0.0652(0.0967) Grad: 47658.8203  LR: 0.00001334  \n",
      "Epoch: [2][400/671] Elapsed 1m 40s (remain 1m 7s) Loss: 0.1279(0.0975) Grad: 40786.8164  LR: 0.00001312  \n",
      "Epoch: [2][420/671] Elapsed 1m 44s (remain 1m 2s) Loss: 0.1532(0.0980) Grad: 54248.3086  LR: 0.00001290  \n",
      "Epoch: [2][440/671] Elapsed 1m 49s (remain 0m 57s) Loss: 0.0670(0.0976) Grad: 32054.9688  LR: 0.00001267  \n",
      "Epoch: [2][460/671] Elapsed 1m 55s (remain 0m 52s) Loss: 0.2259(0.0989) Grad: 87399.1016  LR: 0.00001245  \n",
      "Epoch: [2][480/671] Elapsed 2m 1s (remain 0m 47s) Loss: 0.0568(0.0988) Grad: 17234.5625  LR: 0.00001222  \n",
      "Epoch: [2][500/671] Elapsed 2m 7s (remain 0m 43s) Loss: 0.1126(0.0992) Grad: 55354.2188  LR: 0.00001199  \n",
      "Epoch: [2][520/671] Elapsed 2m 11s (remain 0m 37s) Loss: 0.1739(0.0987) Grad: 53388.5742  LR: 0.00001176  \n",
      "Epoch: [2][540/671] Elapsed 2m 16s (remain 0m 32s) Loss: 0.1177(0.0984) Grad: 36495.0547  LR: 0.00001153  \n",
      "Epoch: [2][560/671] Elapsed 2m 21s (remain 0m 27s) Loss: 0.1200(0.0988) Grad: 47909.9922  LR: 0.00001130  \n",
      "Epoch: [2][580/671] Elapsed 2m 26s (remain 0m 22s) Loss: 0.0432(0.0991) Grad: 10859.6523  LR: 0.00001107  \n",
      "Epoch: [2][600/671] Elapsed 2m 31s (remain 0m 17s) Loss: 0.1611(0.0997) Grad: 59164.5703  LR: 0.00001083  \n",
      "Epoch: [2][620/671] Elapsed 2m 36s (remain 0m 12s) Loss: 0.0972(0.0995) Grad: 68617.3594  LR: 0.00001060  \n",
      "Epoch: [2][640/671] Elapsed 2m 40s (remain 0m 7s) Loss: 0.0799(0.0990) Grad: 58918.9062  LR: 0.00001037  \n",
      "Epoch: [2][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.1038(0.0987) Grad: 57800.3711  LR: 0.00001013  \n",
      "Epoch: [2][670/671] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0990(0.0988) Grad: 39717.1914  LR: 0.00001002  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 56s) Loss: 0.1475(0.1475) \n",
      "EVAL: [20/112] Elapsed 0m 4s (remain 0m 17s) Loss: 0.1018(0.1035) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.1077(0.1050) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1031(0.1051) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0702(0.1068) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.0959(0.1069) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0988  avg_val_loss: 0.1065  time: 189s\n",
      "Epoch 2 - Score: 0.4612  Scores: [0.3913691319159277, 0.531015153989365]\n",
      "Epoch 2 - Save Best Score: 0.4612 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.1179(0.1065) \n",
      "Epoch: [3][0/671] Elapsed 0m 0s (remain 4m 25s) Loss: 0.0713(0.0713) Grad: inf  LR: 0.00001001  \n",
      "Epoch: [3][20/671] Elapsed 0m 5s (remain 2m 53s) Loss: 0.1107(0.0725) Grad: 54772.5000  LR: 0.00000977  \n",
      "Epoch: [3][40/671] Elapsed 0m 11s (remain 3m 0s) Loss: 0.0380(0.0704) Grad: 54666.0938  LR: 0.00000954  \n",
      "Epoch: [3][60/671] Elapsed 0m 16s (remain 2m 44s) Loss: 0.0927(0.0699) Grad: 83195.6953  LR: 0.00000930  \n",
      "Epoch: [3][80/671] Elapsed 0m 22s (remain 2m 42s) Loss: 0.0633(0.0685) Grad: 30393.9922  LR: 0.00000907  \n",
      "Epoch: [3][100/671] Elapsed 0m 26s (remain 2m 31s) Loss: 0.1310(0.0683) Grad: 45537.4375  LR: 0.00000884  \n",
      "Epoch: [3][120/671] Elapsed 0m 31s (remain 2m 24s) Loss: 0.0540(0.0714) Grad: 60687.6758  LR: 0.00000861  \n",
      "Epoch: [3][140/671] Elapsed 0m 36s (remain 2m 18s) Loss: 0.0659(0.0693) Grad: 76643.0625  LR: 0.00000838  \n",
      "Epoch: [3][160/671] Elapsed 0m 41s (remain 2m 13s) Loss: 0.0806(0.0699) Grad: 72636.6719  LR: 0.00000815  \n",
      "Epoch: [3][180/671] Elapsed 0m 46s (remain 2m 6s) Loss: 0.0593(0.0694) Grad: 48512.5000  LR: 0.00000792  \n",
      "Epoch: [3][200/671] Elapsed 0m 51s (remain 2m 0s) Loss: 0.0714(0.0696) Grad: 54332.3398  LR: 0.00000769  \n",
      "Epoch: [3][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0602(0.0688) Grad: 87869.5859  LR: 0.00000746  \n",
      "Epoch: [3][240/671] Elapsed 1m 1s (remain 1m 50s) Loss: 0.0385(0.0681) Grad: 55481.3477  LR: 0.00000724  \n",
      "Epoch: [3][260/671] Elapsed 1m 6s (remain 1m 44s) Loss: 0.0434(0.0670) Grad: 42357.5234  LR: 0.00000701  \n",
      "Epoch: [3][280/671] Elapsed 1m 11s (remain 1m 38s) Loss: 0.0295(0.0659) Grad: 24344.2637  LR: 0.00000679  \n",
      "Epoch: [3][300/671] Elapsed 1m 16s (remain 1m 34s) Loss: 0.1145(0.0649) Grad: 45838.3047  LR: 0.00000657  \n",
      "Epoch: [3][320/671] Elapsed 1m 21s (remain 1m 28s) Loss: 0.0515(0.0646) Grad: 42335.8906  LR: 0.00000635  \n",
      "Epoch: [3][340/671] Elapsed 1m 25s (remain 1m 22s) Loss: 0.0726(0.0635) Grad: 42043.8242  LR: 0.00000613  \n",
      "Epoch: [3][360/671] Elapsed 1m 30s (remain 1m 17s) Loss: 0.0785(0.0631) Grad: 54447.6719  LR: 0.00000592  \n",
      "Epoch: [3][380/671] Elapsed 1m 35s (remain 1m 12s) Loss: 0.0194(0.0631) Grad: 27165.6367  LR: 0.00000571  \n",
      "Epoch: [3][400/671] Elapsed 1m 40s (remain 1m 7s) Loss: 0.0464(0.0632) Grad: 29476.2422  LR: 0.00000550  \n",
      "Epoch: [3][420/671] Elapsed 1m 44s (remain 1m 2s) Loss: 0.0704(0.0631) Grad: 56403.3203  LR: 0.00000529  \n",
      "Epoch: [3][440/671] Elapsed 1m 50s (remain 0m 57s) Loss: 0.0448(0.0632) Grad: 30681.8164  LR: 0.00000508  \n",
      "Epoch: [3][460/671] Elapsed 1m 56s (remain 0m 52s) Loss: 0.1240(0.0641) Grad: 37320.4531  LR: 0.00000488  \n",
      "Epoch: [3][480/671] Elapsed 2m 1s (remain 0m 47s) Loss: 0.0819(0.0638) Grad: 76521.8906  LR: 0.00000468  \n",
      "Epoch: [3][500/671] Elapsed 2m 6s (remain 0m 42s) Loss: 0.0332(0.0633) Grad: 42545.5664  LR: 0.00000449  \n",
      "Epoch: [3][520/671] Elapsed 2m 11s (remain 0m 37s) Loss: 0.0449(0.0632) Grad: 30281.3516  LR: 0.00000429  \n",
      "Epoch: [3][540/671] Elapsed 2m 17s (remain 0m 33s) Loss: 0.0750(0.0632) Grad: 33751.2383  LR: 0.00000410  \n",
      "Epoch: [3][560/671] Elapsed 2m 22s (remain 0m 27s) Loss: 0.0413(0.0629) Grad: 26430.7754  LR: 0.00000392  \n",
      "Epoch: [3][580/671] Elapsed 2m 27s (remain 0m 22s) Loss: 0.0997(0.0628) Grad: 61382.7227  LR: 0.00000373  \n",
      "Epoch: [3][600/671] Elapsed 2m 31s (remain 0m 17s) Loss: 0.0636(0.0624) Grad: 42611.2773  LR: 0.00000355  \n",
      "Epoch: [3][620/671] Elapsed 2m 36s (remain 0m 12s) Loss: 0.0344(0.0622) Grad: 35325.8164  LR: 0.00000337  \n",
      "Epoch: [3][640/671] Elapsed 2m 42s (remain 0m 7s) Loss: 0.0587(0.0625) Grad: 58976.5469  LR: 0.00000320  \n",
      "Epoch: [3][660/671] Elapsed 2m 48s (remain 0m 2s) Loss: 0.0686(0.0627) Grad: 47608.8398  LR: 0.00000303  \n",
      "Epoch: [3][670/671] Elapsed 2m 50s (remain 0m 0s) Loss: 0.0212(0.0623) Grad: 22723.7324  LR: 0.00000295  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 58s) Loss: 0.1252(0.1252) \n",
      "EVAL: [20/112] Elapsed 0m 4s (remain 0m 17s) Loss: 0.0902(0.1033) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.0868(0.1029) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1080(0.1026) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0760(0.1056) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.1120(0.1060) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0623  avg_val_loss: 0.1059  time: 191s\n",
      "Epoch 3 - Score: 0.4604  Scores: [0.3920193611457706, 0.5288446706629243]\n",
      "Epoch 3 - Save Best Score: 0.4604 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.1202(0.1059) \n",
      "Epoch: [4][0/671] Elapsed 0m 0s (remain 4m 11s) Loss: 0.0494(0.0494) Grad: 162650.5312  LR: 0.00000294  \n",
      "Epoch: [4][20/671] Elapsed 0m 5s (remain 2m 45s) Loss: 0.0411(0.0501) Grad: 33161.7773  LR: 0.00000278  \n",
      "Epoch: [4][40/671] Elapsed 0m 10s (remain 2m 46s) Loss: 0.0785(0.0540) Grad: 41894.7148  LR: 0.00000262  \n",
      "Epoch: [4][60/671] Elapsed 0m 15s (remain 2m 36s) Loss: 0.0277(0.0518) Grad: 51501.4922  LR: 0.00000246  \n",
      "Epoch: [4][80/671] Elapsed 0m 20s (remain 2m 29s) Loss: 0.0527(0.0511) Grad: 29750.0059  LR: 0.00000231  \n",
      "Epoch: [4][100/671] Elapsed 0m 25s (remain 2m 25s) Loss: 0.0268(0.0493) Grad: 48245.8516  LR: 0.00000216  \n",
      "Epoch: [4][120/671] Elapsed 0m 30s (remain 2m 16s) Loss: 0.1211(0.0487) Grad: 41899.0312  LR: 0.00000202  \n",
      "Epoch: [4][140/671] Elapsed 0m 35s (remain 2m 14s) Loss: 0.0508(0.0497) Grad: 43730.3242  LR: 0.00000188  \n",
      "Epoch: [4][160/671] Elapsed 0m 40s (remain 2m 9s) Loss: 0.0491(0.0481) Grad: 49097.3516  LR: 0.00000175  \n",
      "Epoch: [4][180/671] Elapsed 0m 45s (remain 2m 4s) Loss: 0.0439(0.0492) Grad: 69376.2734  LR: 0.00000162  \n",
      "Epoch: [4][200/671] Elapsed 0m 51s (remain 1m 59s) Loss: 0.0392(0.0502) Grad: 38320.0234  LR: 0.00000149  \n",
      "Epoch: [4][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0519(0.0500) Grad: 46257.3516  LR: 0.00000137  \n",
      "Epoch: [4][240/671] Elapsed 1m 2s (remain 1m 51s) Loss: 0.0263(0.0494) Grad: 27918.2480  LR: 0.00000125  \n",
      "Epoch: [4][260/671] Elapsed 1m 6s (remain 1m 44s) Loss: 0.0398(0.0492) Grad: 26876.5957  LR: 0.00000114  \n",
      "Epoch: [4][280/671] Elapsed 1m 11s (remain 1m 39s) Loss: 0.0187(0.0485) Grad: 24864.4023  LR: 0.00000104  \n",
      "Epoch: [4][300/671] Elapsed 1m 17s (remain 1m 34s) Loss: 0.0372(0.0485) Grad: 57711.3672  LR: 0.00000094  \n",
      "Epoch: [4][320/671] Elapsed 1m 22s (remain 1m 29s) Loss: 0.0571(0.0489) Grad: 56055.8750  LR: 0.00000084  \n",
      "Epoch: [4][340/671] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0496(0.0485) Grad: 58679.4375  LR: 0.00000075  \n",
      "Epoch: [4][360/671] Elapsed 1m 31s (remain 1m 18s) Loss: 0.0468(0.0483) Grad: 23909.0938  LR: 0.00000066  \n",
      "Epoch: [4][380/671] Elapsed 1m 36s (remain 1m 13s) Loss: 0.0251(0.0480) Grad: 44523.1758  LR: 0.00000058  \n",
      "Epoch: [4][400/671] Elapsed 1m 42s (remain 1m 8s) Loss: 0.0572(0.0479) Grad: 49483.0039  LR: 0.00000051  \n",
      "Epoch: [4][420/671] Elapsed 1m 46s (remain 1m 3s) Loss: 0.0489(0.0480) Grad: 43639.0664  LR: 0.00000043  \n",
      "Epoch: [4][440/671] Elapsed 1m 52s (remain 0m 58s) Loss: 0.0243(0.0479) Grad: 48953.7930  LR: 0.00000037  \n",
      "Epoch: [4][460/671] Elapsed 1m 56s (remain 0m 53s) Loss: 0.0361(0.0478) Grad: 29144.4746  LR: 0.00000031  \n",
      "Epoch: [4][480/671] Elapsed 2m 1s (remain 0m 48s) Loss: 0.0767(0.0478) Grad: 75978.4062  LR: 0.00000025  \n",
      "Epoch: [4][500/671] Elapsed 2m 7s (remain 0m 43s) Loss: 0.0535(0.0478) Grad: 37077.8984  LR: 0.00000020  \n",
      "Epoch: [4][520/671] Elapsed 2m 12s (remain 0m 38s) Loss: 0.0339(0.0476) Grad: 40796.5508  LR: 0.00000016  \n",
      "Epoch: [4][540/671] Elapsed 2m 17s (remain 0m 33s) Loss: 0.0449(0.0477) Grad: 50113.6211  LR: 0.00000012  \n",
      "Epoch: [4][560/671] Elapsed 2m 22s (remain 0m 27s) Loss: 0.0522(0.0477) Grad: 68782.5781  LR: 0.00000009  \n",
      "Epoch: [4][580/671] Elapsed 2m 27s (remain 0m 22s) Loss: 0.0341(0.0475) Grad: 24662.8184  LR: 0.00000006  \n",
      "Epoch: [4][600/671] Elapsed 2m 33s (remain 0m 17s) Loss: 0.0331(0.0475) Grad: 51606.7461  LR: 0.00000004  \n",
      "Epoch: [4][620/671] Elapsed 2m 38s (remain 0m 12s) Loss: 0.1004(0.0476) Grad: 71916.7891  LR: 0.00000002  \n",
      "Epoch: [4][640/671] Elapsed 2m 43s (remain 0m 7s) Loss: 0.0642(0.0475) Grad: 51541.2070  LR: 0.00000001  \n",
      "Epoch: [4][660/671] Elapsed 2m 48s (remain 0m 2s) Loss: 0.0368(0.0473) Grad: 47338.9375  LR: 0.00000000  \n",
      "Epoch: [4][670/671] Elapsed 2m 50s (remain 0m 0s) Loss: 0.0339(0.0471) Grad: 43174.9805  LR: 0.00000000  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 1m 0s) Loss: 0.1399(0.1399) \n",
      "EVAL: [20/112] Elapsed 0m 4s (remain 0m 17s) Loss: 0.0925(0.1027) \n",
      "EVAL: [40/112] Elapsed 0m 8s (remain 0m 13s) Loss: 0.0846(0.1029) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1078(0.1027) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0725(0.1060) \n",
      "EVAL: [100/112] Elapsed 0m 17s (remain 0m 1s) Loss: 0.1161(0.1062) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0471  avg_val_loss: 0.1059  time: 191s\n",
      "Epoch 4 - Score: 0.4604  Scores: [0.39033256855935816, 0.5303833135291249]\n",
      "Epoch 4 - Save Best Score: 0.4604 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 19s (remain 0m 0s) Loss: 0.1172(0.1059) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 0.4604  Scores: [0.39033256855935816, 0.5303833135291249]\n",
      "========== CV ==========\n",
      "Score: 0.4613  Scores: [0.3905521387305545, 0.532068062430999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2 Experiment: base-deberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9265ef6a9a349df94f1d18bf5a0fd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 512\n",
      "========== fold: 2 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/671] Elapsed 0m 0s (remain 5m 24s) Loss: 0.6931(0.6931) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/671] Elapsed 0m 5s (remain 2m 38s) Loss: 0.2607(0.3963) Grad: 34166.5312  LR: 0.00002000  \n",
      "Epoch: [1][40/671] Elapsed 0m 10s (remain 2m 45s) Loss: 0.1663(0.3288) Grad: 56802.9688  LR: 0.00001999  \n",
      "Epoch: [1][60/671] Elapsed 0m 15s (remain 2m 32s) Loss: 0.3093(0.2822) Grad: 78728.9766  LR: 0.00001997  \n",
      "Epoch: [1][80/671] Elapsed 0m 20s (remain 2m 31s) Loss: 0.2004(0.2586) Grad: 62329.9023  LR: 0.00001996  \n",
      "Epoch: [1][100/671] Elapsed 0m 25s (remain 2m 24s) Loss: 0.1041(0.2396) Grad: 25687.9512  LR: 0.00001993  \n",
      "Epoch: [1][120/671] Elapsed 0m 30s (remain 2m 19s) Loss: 0.1133(0.2303) Grad: 60985.9922  LR: 0.00001990  \n",
      "Epoch: [1][140/671] Elapsed 0m 35s (remain 2m 14s) Loss: 0.1640(0.2160) Grad: 53361.0312  LR: 0.00001986  \n",
      "Epoch: [1][160/671] Elapsed 0m 41s (remain 2m 10s) Loss: 0.1054(0.2122) Grad: 25874.8711  LR: 0.00001982  \n",
      "Epoch: [1][180/671] Elapsed 0m 45s (remain 2m 4s) Loss: 0.2584(0.2072) Grad: 49604.6758  LR: 0.00001978  \n",
      "Epoch: [1][200/671] Elapsed 0m 50s (remain 1m 58s) Loss: 0.1011(0.2006) Grad: 26987.4668  LR: 0.00001972  \n",
      "Epoch: [1][220/671] Elapsed 0m 55s (remain 1m 53s) Loss: 0.1131(0.1958) Grad: 35987.9297  LR: 0.00001967  \n",
      "Epoch: [1][240/671] Elapsed 1m 1s (remain 1m 50s) Loss: 0.0978(0.1919) Grad: 47678.9414  LR: 0.00001961  \n",
      "Epoch: [1][260/671] Elapsed 1m 6s (remain 1m 44s) Loss: 0.0938(0.1870) Grad: 51167.7734  LR: 0.00001954  \n",
      "Epoch: [1][280/671] Elapsed 1m 11s (remain 1m 39s) Loss: 0.1566(0.1845) Grad: 33564.4062  LR: 0.00001946  \n",
      "Epoch: [1][300/671] Elapsed 1m 16s (remain 1m 33s) Loss: 0.3460(0.1831) Grad: 78043.4453  LR: 0.00001939  \n",
      "Epoch: [1][320/671] Elapsed 1m 21s (remain 1m 29s) Loss: 0.0655(0.1804) Grad: 19209.5781  LR: 0.00001930  \n",
      "Epoch: [1][340/671] Elapsed 1m 26s (remain 1m 23s) Loss: 0.1402(0.1777) Grad: 64925.7812  LR: 0.00001922  \n",
      "Epoch: [1][360/671] Elapsed 1m 31s (remain 1m 18s) Loss: 0.3295(0.1756) Grad: 72087.9141  LR: 0.00001912  \n",
      "Epoch: [1][380/671] Elapsed 1m 36s (remain 1m 13s) Loss: 0.1005(0.1737) Grad: 34915.4805  LR: 0.00001902  \n",
      "Epoch: [1][400/671] Elapsed 1m 41s (remain 1m 8s) Loss: 0.1521(0.1713) Grad: 34946.6094  LR: 0.00001892  \n",
      "Epoch: [1][420/671] Elapsed 1m 45s (remain 1m 2s) Loss: 0.2179(0.1709) Grad: 62554.3281  LR: 0.00001881  \n",
      "Epoch: [1][440/671] Elapsed 1m 50s (remain 0m 57s) Loss: 0.1072(0.1691) Grad: 50491.7852  LR: 0.00001870  \n",
      "Epoch: [1][460/671] Elapsed 1m 55s (remain 0m 52s) Loss: 0.1029(0.1685) Grad: 36124.8164  LR: 0.00001858  \n",
      "Epoch: [1][480/671] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0770(0.1694) Grad: 27422.7383  LR: 0.00001846  \n",
      "Epoch: [1][500/671] Elapsed 2m 5s (remain 0m 42s) Loss: 0.0715(0.1677) Grad: 13755.0469  LR: 0.00001833  \n",
      "Epoch: [1][520/671] Elapsed 2m 10s (remain 0m 37s) Loss: 0.1484(0.1659) Grad: 30149.7402  LR: 0.00001820  \n",
      "Epoch: [1][540/671] Elapsed 2m 14s (remain 0m 32s) Loss: 0.1578(0.1649) Grad: 31133.4473  LR: 0.00001806  \n",
      "Epoch: [1][560/671] Elapsed 2m 19s (remain 0m 27s) Loss: 0.0510(0.1632) Grad: 19828.3848  LR: 0.00001792  \n",
      "Epoch: [1][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.1065(0.1622) Grad: 31996.6973  LR: 0.00001778  \n",
      "Epoch: [1][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.0816(0.1611) Grad: 54318.9141  LR: 0.00001763  \n",
      "Epoch: [1][620/671] Elapsed 2m 35s (remain 0m 12s) Loss: 0.0643(0.1596) Grad: 29809.4336  LR: 0.00001748  \n",
      "Epoch: [1][640/671] Elapsed 2m 40s (remain 0m 7s) Loss: 0.1775(0.1586) Grad: 21291.2227  LR: 0.00001732  \n",
      "Epoch: [1][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.1637(0.1582) Grad: 67819.0391  LR: 0.00001716  \n",
      "Epoch: [1][670/671] Elapsed 2m 47s (remain 0m 0s) Loss: 0.1219(0.1573) Grad: 49988.8203  LR: 0.00001708  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 54s) Loss: 0.1968(0.1968) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 15s) Loss: 0.1234(0.1324) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.1405(0.1352) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1742(0.1359) \n",
      "EVAL: [80/112] Elapsed 0m 15s (remain 0m 5s) Loss: 0.1523(0.1375) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0778(0.1376) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.1573  avg_val_loss: 0.1371  time: 189s\n",
      "Epoch 1 - Score: 0.5340  Scores: [0.5093164178882102, 0.5587244422472643]\n",
      "Epoch 1 - Save Best Score: 0.5340 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.1642(0.1371) \n",
      "Epoch: [2][0/671] Elapsed 0m 0s (remain 6m 30s) Loss: 0.0848(0.0848) Grad: inf  LR: 0.00001707  \n",
      "Epoch: [2][20/671] Elapsed 0m 4s (remain 2m 16s) Loss: 0.0519(0.1131) Grad: 73867.8594  LR: 0.00001690  \n",
      "Epoch: [2][40/671] Elapsed 0m 8s (remain 2m 14s) Loss: 0.0425(0.1026) Grad: 70432.1250  LR: 0.00001673  \n",
      "Epoch: [2][60/671] Elapsed 0m 13s (remain 2m 19s) Loss: 0.1236(0.1009) Grad: 53404.1016  LR: 0.00001655  \n",
      "Epoch: [2][80/671] Elapsed 0m 19s (remain 2m 22s) Loss: 0.0729(0.0945) Grad: 55186.5625  LR: 0.00001637  \n",
      "Epoch: [2][100/671] Elapsed 0m 24s (remain 2m 20s) Loss: 0.0805(0.0962) Grad: 67305.9922  LR: 0.00001619  \n",
      "Epoch: [2][120/671] Elapsed 0m 29s (remain 2m 12s) Loss: 0.1945(0.0968) Grad: 43047.0664  LR: 0.00001601  \n",
      "Epoch: [2][140/671] Elapsed 0m 33s (remain 2m 7s) Loss: 0.1304(0.0974) Grad: 66137.1094  LR: 0.00001582  \n",
      "Epoch: [2][160/671] Elapsed 0m 38s (remain 2m 3s) Loss: 0.0714(0.0968) Grad: 65904.9531  LR: 0.00001563  \n",
      "Epoch: [2][180/671] Elapsed 0m 43s (remain 1m 58s) Loss: 0.1005(0.0967) Grad: 51547.4648  LR: 0.00001543  \n",
      "Epoch: [2][200/671] Elapsed 0m 49s (remain 1m 55s) Loss: 0.0752(0.0966) Grad: 56037.8359  LR: 0.00001523  \n",
      "Epoch: [2][220/671] Elapsed 0m 54s (remain 1m 50s) Loss: 0.0432(0.0962) Grad: 37265.8672  LR: 0.00001503  \n",
      "Epoch: [2][240/671] Elapsed 0m 58s (remain 1m 44s) Loss: 0.0533(0.0942) Grad: 47647.6328  LR: 0.00001483  \n",
      "Epoch: [2][260/671] Elapsed 1m 4s (remain 1m 40s) Loss: 0.0390(0.0947) Grad: 52456.3398  LR: 0.00001462  \n",
      "Epoch: [2][280/671] Elapsed 1m 8s (remain 1m 35s) Loss: 0.1279(0.0931) Grad: 151149.1406  LR: 0.00001442  \n",
      "Epoch: [2][300/671] Elapsed 1m 13s (remain 1m 30s) Loss: 0.1258(0.0931) Grad: 74028.7891  LR: 0.00001420  \n",
      "Epoch: [2][320/671] Elapsed 1m 18s (remain 1m 26s) Loss: 0.0763(0.0931) Grad: 58547.9453  LR: 0.00001399  \n",
      "Epoch: [2][340/671] Elapsed 1m 24s (remain 1m 21s) Loss: 0.0978(0.0937) Grad: 61308.6484  LR: 0.00001378  \n",
      "Epoch: [2][360/671] Elapsed 1m 29s (remain 1m 16s) Loss: 0.0814(0.0938) Grad: 65924.7734  LR: 0.00001356  \n",
      "Epoch: [2][380/671] Elapsed 1m 34s (remain 1m 11s) Loss: 0.0640(0.0942) Grad: 39778.5000  LR: 0.00001334  \n",
      "Epoch: [2][400/671] Elapsed 1m 39s (remain 1m 7s) Loss: 0.1846(0.0940) Grad: 42734.6055  LR: 0.00001312  \n",
      "Epoch: [2][420/671] Elapsed 1m 44s (remain 1m 2s) Loss: 0.2204(0.0943) Grad: 68948.6953  LR: 0.00001289  \n",
      "Epoch: [2][440/671] Elapsed 1m 49s (remain 0m 57s) Loss: 0.1056(0.0947) Grad: 58584.9180  LR: 0.00001267  \n",
      "Epoch: [2][460/671] Elapsed 1m 54s (remain 0m 52s) Loss: 0.1518(0.0947) Grad: 48315.5312  LR: 0.00001244  \n",
      "Epoch: [2][480/671] Elapsed 1m 59s (remain 0m 47s) Loss: 0.1126(0.0952) Grad: 19340.1113  LR: 0.00001222  \n",
      "Epoch: [2][500/671] Elapsed 2m 4s (remain 0m 42s) Loss: 0.0952(0.0952) Grad: 39405.9531  LR: 0.00001199  \n",
      "Epoch: [2][520/671] Elapsed 2m 9s (remain 0m 37s) Loss: 0.0678(0.0959) Grad: 21868.3965  LR: 0.00001176  \n",
      "Epoch: [2][540/671] Elapsed 2m 14s (remain 0m 32s) Loss: 0.0735(0.0959) Grad: 25681.1367  LR: 0.00001153  \n",
      "Epoch: [2][560/671] Elapsed 2m 18s (remain 0m 27s) Loss: 0.1156(0.0954) Grad: 57571.0703  LR: 0.00001129  \n",
      "Epoch: [2][580/671] Elapsed 2m 23s (remain 0m 22s) Loss: 0.1256(0.0963) Grad: 43824.4961  LR: 0.00001106  \n",
      "Epoch: [2][600/671] Elapsed 2m 28s (remain 0m 17s) Loss: 0.0766(0.0959) Grad: 22017.2598  LR: 0.00001083  \n",
      "Epoch: [2][620/671] Elapsed 2m 34s (remain 0m 12s) Loss: 0.1003(0.0958) Grad: 57888.1875  LR: 0.00001060  \n",
      "Epoch: [2][640/671] Elapsed 2m 39s (remain 0m 7s) Loss: 0.0818(0.0957) Grad: 30984.5156  LR: 0.00001036  \n",
      "Epoch: [2][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.0809(0.0961) Grad: 26334.2852  LR: 0.00001013  \n",
      "Epoch: [2][670/671] Elapsed 2m 47s (remain 0m 0s) Loss: 0.3757(0.0965) Grad: 54933.4141  LR: 0.00001001  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 55s) Loss: 0.1552(0.1552) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 16s) Loss: 0.1003(0.1132) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.1258(0.1164) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1486(0.1173) \n",
      "EVAL: [80/112] Elapsed 0m 15s (remain 0m 5s) Loss: 0.1251(0.1186) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0638(0.1184) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0965  avg_val_loss: 0.1177  time: 189s\n",
      "Epoch 2 - Score: 0.4898  Scores: [0.4400002764251101, 0.5396139143549323]\n",
      "Epoch 2 - Save Best Score: 0.4898 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.1405(0.1177) \n",
      "Epoch: [3][0/671] Elapsed 0m 0s (remain 5m 3s) Loss: 0.0589(0.0589) Grad: inf  LR: 0.00001000  \n",
      "Epoch: [3][20/671] Elapsed 0m 5s (remain 2m 46s) Loss: 0.0756(0.0803) Grad: 49253.4688  LR: 0.00000977  \n",
      "Epoch: [3][40/671] Elapsed 0m 10s (remain 2m 39s) Loss: 0.0405(0.0832) Grad: 54439.0391  LR: 0.00000953  \n",
      "Epoch: [3][60/671] Elapsed 0m 15s (remain 2m 36s) Loss: 0.0919(0.0812) Grad: 73664.6250  LR: 0.00000930  \n",
      "Epoch: [3][80/671] Elapsed 0m 20s (remain 2m 27s) Loss: 0.0578(0.0761) Grad: 44390.3320  LR: 0.00000907  \n",
      "Epoch: [3][100/671] Elapsed 0m 26s (remain 2m 27s) Loss: 0.1746(0.0741) Grad: 76095.8828  LR: 0.00000883  \n",
      "Epoch: [3][120/671] Elapsed 0m 31s (remain 2m 22s) Loss: 0.0396(0.0740) Grad: 44297.1289  LR: 0.00000860  \n",
      "Epoch: [3][140/671] Elapsed 0m 36s (remain 2m 15s) Loss: 0.0581(0.0729) Grad: 73263.3438  LR: 0.00000837  \n",
      "Epoch: [3][160/671] Elapsed 0m 40s (remain 2m 9s) Loss: 0.0853(0.0718) Grad: 104783.0000  LR: 0.00000814  \n",
      "Epoch: [3][180/671] Elapsed 0m 44s (remain 2m 1s) Loss: 0.0416(0.0707) Grad: 35465.4883  LR: 0.00000791  \n",
      "Epoch: [3][200/671] Elapsed 0m 49s (remain 1m 55s) Loss: 0.0370(0.0700) Grad: 27666.1758  LR: 0.00000768  \n",
      "Epoch: [3][220/671] Elapsed 0m 54s (remain 1m 50s) Loss: 0.0229(0.0684) Grad: 24399.3262  LR: 0.00000746  \n",
      "Epoch: [3][240/671] Elapsed 0m 59s (remain 1m 45s) Loss: 0.0698(0.0692) Grad: 50922.3906  LR: 0.00000723  \n",
      "Epoch: [3][260/671] Elapsed 1m 4s (remain 1m 41s) Loss: 0.0557(0.0691) Grad: 46007.8008  LR: 0.00000701  \n",
      "Epoch: [3][280/671] Elapsed 1m 9s (remain 1m 36s) Loss: 0.0276(0.0688) Grad: 20086.6074  LR: 0.00000678  \n",
      "Epoch: [3][300/671] Elapsed 1m 14s (remain 1m 32s) Loss: 0.0900(0.0682) Grad: 27568.3535  LR: 0.00000656  \n",
      "Epoch: [3][320/671] Elapsed 1m 20s (remain 1m 27s) Loss: 0.0365(0.0683) Grad: 16594.2930  LR: 0.00000634  \n",
      "Epoch: [3][340/671] Elapsed 1m 25s (remain 1m 22s) Loss: 0.0465(0.0683) Grad: 34172.5664  LR: 0.00000613  \n",
      "Epoch: [3][360/671] Elapsed 1m 30s (remain 1m 17s) Loss: 0.0327(0.0679) Grad: 42661.4336  LR: 0.00000591  \n",
      "Epoch: [3][380/671] Elapsed 1m 34s (remain 1m 11s) Loss: 0.0677(0.0673) Grad: 50094.6562  LR: 0.00000570  \n",
      "Epoch: [3][400/671] Elapsed 1m 39s (remain 1m 6s) Loss: 0.0392(0.0672) Grad: 41292.2461  LR: 0.00000549  \n",
      "Epoch: [3][420/671] Elapsed 1m 43s (remain 1m 1s) Loss: 0.1781(0.0671) Grad: 98100.4219  LR: 0.00000528  \n",
      "Epoch: [3][440/671] Elapsed 1m 48s (remain 0m 56s) Loss: 0.0742(0.0673) Grad: 60492.6094  LR: 0.00000508  \n",
      "Epoch: [3][460/671] Elapsed 1m 53s (remain 0m 51s) Loss: 0.0293(0.0667) Grad: 30345.9219  LR: 0.00000488  \n",
      "Epoch: [3][480/671] Elapsed 1m 58s (remain 0m 46s) Loss: 0.0542(0.0668) Grad: 54908.2461  LR: 0.00000468  \n",
      "Epoch: [3][500/671] Elapsed 2m 4s (remain 0m 42s) Loss: 0.0588(0.0668) Grad: 32826.2461  LR: 0.00000448  \n",
      "Epoch: [3][520/671] Elapsed 2m 9s (remain 0m 37s) Loss: 0.1153(0.0669) Grad: 98888.3281  LR: 0.00000429  \n",
      "Epoch: [3][540/671] Elapsed 2m 14s (remain 0m 32s) Loss: 0.0304(0.0663) Grad: 30750.6465  LR: 0.00000410  \n",
      "Epoch: [3][560/671] Elapsed 2m 19s (remain 0m 27s) Loss: 0.0365(0.0659) Grad: 20208.6191  LR: 0.00000391  \n",
      "Epoch: [3][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.0354(0.0660) Grad: 32402.0586  LR: 0.00000372  \n",
      "Epoch: [3][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.1140(0.0661) Grad: 113053.2500  LR: 0.00000354  \n",
      "Epoch: [3][620/671] Elapsed 2m 36s (remain 0m 12s) Loss: 0.0618(0.0665) Grad: 30533.9395  LR: 0.00000337  \n",
      "Epoch: [3][640/671] Elapsed 2m 41s (remain 0m 7s) Loss: 0.0655(0.0668) Grad: 46099.2422  LR: 0.00000319  \n",
      "Epoch: [3][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.0485(0.0666) Grad: 34652.3320  LR: 0.00000302  \n",
      "Epoch: [3][670/671] Elapsed 2m 47s (remain 0m 0s) Loss: 0.0909(0.0666) Grad: 46296.9258  LR: 0.00000294  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 42s) Loss: 0.1327(0.1327) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 15s) Loss: 0.0736(0.1084) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.1185(0.1105) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1180(0.1110) \n",
      "EVAL: [80/112] Elapsed 0m 15s (remain 0m 5s) Loss: 0.1145(0.1117) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0756(0.1124) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0666  avg_val_loss: 0.1114  time: 189s\n",
      "Epoch 3 - Score: 0.4728  Scores: [0.4038102725430311, 0.5417295610993825]\n",
      "Epoch 3 - Save Best Score: 0.4728 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.1390(0.1114) \n",
      "Epoch: [4][0/671] Elapsed 0m 0s (remain 5m 54s) Loss: 0.0552(0.0552) Grad: 213525.4688  LR: 0.00000293  \n",
      "Epoch: [4][20/671] Elapsed 0m 5s (remain 2m 51s) Loss: 0.0669(0.0507) Grad: 34846.8125  LR: 0.00000277  \n",
      "Epoch: [4][40/671] Elapsed 0m 11s (remain 2m 51s) Loss: 0.0486(0.0513) Grad: 69962.7891  LR: 0.00000261  \n",
      "Epoch: [4][60/671] Elapsed 0m 16s (remain 2m 42s) Loss: 0.1099(0.0507) Grad: 46841.7422  LR: 0.00000245  \n",
      "Epoch: [4][80/671] Elapsed 0m 20s (remain 2m 31s) Loss: 0.0376(0.0491) Grad: 54808.8203  LR: 0.00000230  \n",
      "Epoch: [4][100/671] Elapsed 0m 25s (remain 2m 25s) Loss: 0.0309(0.0485) Grad: 26338.7246  LR: 0.00000216  \n",
      "Epoch: [4][120/671] Elapsed 0m 31s (remain 2m 23s) Loss: 0.0553(0.0490) Grad: 32472.2051  LR: 0.00000201  \n",
      "Epoch: [4][140/671] Elapsed 0m 37s (remain 2m 19s) Loss: 0.0636(0.0482) Grad: 27649.2207  LR: 0.00000187  \n",
      "Epoch: [4][160/671] Elapsed 0m 41s (remain 2m 11s) Loss: 0.0297(0.0482) Grad: 36675.2812  LR: 0.00000174  \n",
      "Epoch: [4][180/671] Elapsed 0m 46s (remain 2m 6s) Loss: 0.0428(0.0493) Grad: 51084.2109  LR: 0.00000161  \n",
      "Epoch: [4][200/671] Elapsed 0m 51s (remain 1m 59s) Loss: 0.0276(0.0487) Grad: 21044.8906  LR: 0.00000149  \n",
      "Epoch: [4][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0562(0.0489) Grad: 58677.4141  LR: 0.00000137  \n",
      "Epoch: [4][240/671] Elapsed 1m 1s (remain 1m 50s) Loss: 0.0539(0.0495) Grad: 42393.8594  LR: 0.00000125  \n",
      "Epoch: [4][260/671] Elapsed 1m 6s (remain 1m 44s) Loss: 0.0599(0.0493) Grad: 46304.3242  LR: 0.00000114  \n",
      "Epoch: [4][280/671] Elapsed 1m 11s (remain 1m 39s) Loss: 0.0620(0.0495) Grad: 47185.7891  LR: 0.00000103  \n",
      "Epoch: [4][300/671] Elapsed 1m 16s (remain 1m 34s) Loss: 0.0261(0.0492) Grad: 17626.1191  LR: 0.00000093  \n",
      "Epoch: [4][320/671] Elapsed 1m 21s (remain 1m 29s) Loss: 0.0283(0.0491) Grad: 30568.3066  LR: 0.00000084  \n",
      "Epoch: [4][340/671] Elapsed 1m 26s (remain 1m 24s) Loss: 0.0300(0.0488) Grad: 37507.3672  LR: 0.00000074  \n",
      "Epoch: [4][360/671] Elapsed 1m 32s (remain 1m 19s) Loss: 0.0425(0.0486) Grad: 42274.2773  LR: 0.00000066  \n",
      "Epoch: [4][380/671] Elapsed 1m 37s (remain 1m 13s) Loss: 0.0338(0.0487) Grad: 47882.3242  LR: 0.00000058  \n",
      "Epoch: [4][400/671] Elapsed 1m 42s (remain 1m 8s) Loss: 0.0732(0.0491) Grad: 64708.1641  LR: 0.00000050  \n",
      "Epoch: [4][420/671] Elapsed 1m 47s (remain 1m 3s) Loss: 0.0439(0.0491) Grad: 33490.2656  LR: 0.00000043  \n",
      "Epoch: [4][440/671] Elapsed 1m 52s (remain 0m 58s) Loss: 0.0606(0.0494) Grad: 55957.9961  LR: 0.00000037  \n",
      "Epoch: [4][460/671] Elapsed 1m 57s (remain 0m 53s) Loss: 0.0222(0.0497) Grad: 31049.0859  LR: 0.00000031  \n",
      "Epoch: [4][480/671] Elapsed 2m 2s (remain 0m 48s) Loss: 0.0391(0.0492) Grad: 28465.8691  LR: 0.00000025  \n",
      "Epoch: [4][500/671] Elapsed 2m 7s (remain 0m 43s) Loss: 0.0311(0.0499) Grad: 27762.2715  LR: 0.00000020  \n",
      "Epoch: [4][520/671] Elapsed 2m 12s (remain 0m 38s) Loss: 0.0464(0.0499) Grad: 35796.1016  LR: 0.00000016  \n",
      "Epoch: [4][540/671] Elapsed 2m 16s (remain 0m 32s) Loss: 0.0447(0.0496) Grad: 46774.9023  LR: 0.00000012  \n",
      "Epoch: [4][560/671] Elapsed 2m 21s (remain 0m 27s) Loss: 0.1146(0.0498) Grad: 59456.1602  LR: 0.00000009  \n",
      "Epoch: [4][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.0617(0.0497) Grad: 56170.5352  LR: 0.00000006  \n",
      "Epoch: [4][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.0335(0.0499) Grad: 60714.4844  LR: 0.00000004  \n",
      "Epoch: [4][620/671] Elapsed 2m 35s (remain 0m 12s) Loss: 0.1483(0.0501) Grad: 100031.6328  LR: 0.00000002  \n",
      "Epoch: [4][640/671] Elapsed 2m 40s (remain 0m 7s) Loss: 0.0395(0.0501) Grad: 45950.2578  LR: 0.00000001  \n",
      "Epoch: [4][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.0259(0.0499) Grad: 26420.4414  LR: 0.00000000  \n",
      "Epoch: [4][670/671] Elapsed 2m 48s (remain 0m 0s) Loss: 0.1086(0.0501) Grad: 108555.9688  LR: 0.00000000  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 45s) Loss: 0.1324(0.1324) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 15s) Loss: 0.0752(0.1093) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 13s) Loss: 0.1151(0.1114) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1260(0.1117) \n",
      "EVAL: [80/112] Elapsed 0m 15s (remain 0m 5s) Loss: 0.1125(0.1122) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0766(0.1132) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0501  avg_val_loss: 0.1124  time: 189s\n",
      "Epoch 4 - Score: 0.4751  Scores: [0.4066128578264426, 0.543614456503248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.1379(0.1124) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 0.4728  Scores: [0.4038102725430311, 0.5417295610993825]\n",
      "========== CV ==========\n",
      "Score: 0.4652  Scores: [0.3950226161753696, 0.5353091394955385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3 Experiment: base-deberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd72b209656d4106ab40fbde25ee3a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 512\n",
      "========== fold: 3 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/671] Elapsed 0m 0s (remain 4m 51s) Loss: 0.5084(0.5084) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/671] Elapsed 0m 5s (remain 2m 41s) Loss: 0.3440(0.4188) Grad: 32330.7324  LR: 0.00002000  \n",
      "Epoch: [1][40/671] Elapsed 0m 10s (remain 2m 33s) Loss: 0.2335(0.3669) Grad: 32973.9922  LR: 0.00001999  \n",
      "Epoch: [1][60/671] Elapsed 0m 16s (remain 2m 41s) Loss: 0.2589(0.3135) Grad: 57234.6953  LR: 0.00001997  \n",
      "Epoch: [1][80/671] Elapsed 0m 21s (remain 2m 37s) Loss: 0.2748(0.2782) Grad: 42711.0977  LR: 0.00001996  \n",
      "Epoch: [1][100/671] Elapsed 0m 26s (remain 2m 31s) Loss: 0.0847(0.2516) Grad: 22631.1270  LR: 0.00001993  \n",
      "Epoch: [1][120/671] Elapsed 0m 31s (remain 2m 24s) Loss: 0.2397(0.2343) Grad: 41193.8594  LR: 0.00001990  \n",
      "Epoch: [1][140/671] Elapsed 0m 36s (remain 2m 18s) Loss: 0.2183(0.2286) Grad: 32892.6055  LR: 0.00001986  \n",
      "Epoch: [1][160/671] Elapsed 0m 41s (remain 2m 11s) Loss: 0.0753(0.2203) Grad: 15538.1494  LR: 0.00001982  \n",
      "Epoch: [1][180/671] Elapsed 0m 46s (remain 2m 6s) Loss: 0.2116(0.2149) Grad: 48644.7930  LR: 0.00001978  \n",
      "Epoch: [1][200/671] Elapsed 0m 50s (remain 1m 59s) Loss: 0.0693(0.2086) Grad: 25627.4082  LR: 0.00001973  \n",
      "Epoch: [1][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0918(0.2027) Grad: 24023.1777  LR: 0.00001967  \n",
      "Epoch: [1][240/671] Elapsed 1m 2s (remain 1m 51s) Loss: 0.0568(0.1961) Grad: 16002.9590  LR: 0.00001961  \n",
      "Epoch: [1][260/671] Elapsed 1m 7s (remain 1m 46s) Loss: 0.2168(0.1928) Grad: 40792.9180  LR: 0.00001954  \n",
      "Epoch: [1][280/671] Elapsed 1m 12s (remain 1m 41s) Loss: 0.1066(0.1914) Grad: 23239.7090  LR: 0.00001947  \n",
      "Epoch: [1][300/671] Elapsed 1m 17s (remain 1m 35s) Loss: 0.1129(0.1885) Grad: 33351.6367  LR: 0.00001939  \n",
      "Epoch: [1][320/671] Elapsed 1m 22s (remain 1m 30s) Loss: 0.0714(0.1841) Grad: 36284.2734  LR: 0.00001930  \n",
      "Epoch: [1][340/671] Elapsed 1m 27s (remain 1m 24s) Loss: 0.1573(0.1824) Grad: 67797.0469  LR: 0.00001922  \n",
      "Epoch: [1][360/671] Elapsed 1m 31s (remain 1m 18s) Loss: 0.0873(0.1796) Grad: 60304.4688  LR: 0.00001912  \n",
      "Epoch: [1][380/671] Elapsed 1m 36s (remain 1m 13s) Loss: 0.1590(0.1771) Grad: 31313.2090  LR: 0.00001902  \n",
      "Epoch: [1][400/671] Elapsed 1m 41s (remain 1m 8s) Loss: 0.1937(0.1760) Grad: 67841.8516  LR: 0.00001892  \n",
      "Epoch: [1][420/671] Elapsed 1m 46s (remain 1m 3s) Loss: 0.1572(0.1736) Grad: 26845.5156  LR: 0.00001881  \n",
      "Epoch: [1][440/671] Elapsed 1m 52s (remain 0m 58s) Loss: 0.0701(0.1723) Grad: 42659.6289  LR: 0.00001870  \n",
      "Epoch: [1][460/671] Elapsed 1m 56s (remain 0m 53s) Loss: 0.0593(0.1694) Grad: 31038.1504  LR: 0.00001858  \n",
      "Epoch: [1][480/671] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0853(0.1670) Grad: 46242.2070  LR: 0.00001846  \n",
      "Epoch: [1][500/671] Elapsed 2m 5s (remain 0m 42s) Loss: 0.2035(0.1653) Grad: 38588.3242  LR: 0.00001833  \n",
      "Epoch: [1][520/671] Elapsed 2m 11s (remain 0m 37s) Loss: 0.1426(0.1646) Grad: 25662.4844  LR: 0.00001820  \n",
      "Epoch: [1][540/671] Elapsed 2m 15s (remain 0m 32s) Loss: 0.1752(0.1651) Grad: 49797.5898  LR: 0.00001807  \n",
      "Epoch: [1][560/671] Elapsed 2m 20s (remain 0m 27s) Loss: 0.1178(0.1646) Grad: 50852.1641  LR: 0.00001792  \n",
      "Epoch: [1][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.0783(0.1633) Grad: 20174.8145  LR: 0.00001778  \n",
      "Epoch: [1][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.0684(0.1618) Grad: 14629.5850  LR: 0.00001763  \n",
      "Epoch: [1][620/671] Elapsed 2m 35s (remain 0m 12s) Loss: 0.2027(0.1607) Grad: 43052.1172  LR: 0.00001748  \n",
      "Epoch: [1][640/671] Elapsed 2m 40s (remain 0m 7s) Loss: 0.1323(0.1593) Grad: 23466.3965  LR: 0.00001732  \n",
      "Epoch: [1][660/671] Elapsed 2m 45s (remain 0m 2s) Loss: 0.2905(0.1588) Grad: 64929.8672  LR: 0.00001716  \n",
      "Epoch: [1][670/671] Elapsed 2m 47s (remain 0m 0s) Loss: 0.1743(0.1583) Grad: 22289.0371  LR: 0.00001708  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 49s) Loss: 0.2839(0.2839) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 17s) Loss: 0.1923(0.1435) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 12s) Loss: 0.1560(0.1452) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1790(0.1456) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0888(0.1428) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0967(0.1368) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.1583  avg_val_loss: 0.1367  time: 189s\n",
      "Epoch 1 - Score: 0.5327  Scores: [0.4654786759729373, 0.5998466990821216]\n",
      "Epoch 1 - Save Best Score: 0.5327 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.1551(0.1367) \n",
      "Epoch: [2][0/671] Elapsed 0m 0s (remain 8m 6s) Loss: 0.2238(0.2238) Grad: inf  LR: 0.00001707  \n",
      "Epoch: [2][20/671] Elapsed 0m 4s (remain 2m 25s) Loss: 0.0710(0.1148) Grad: 52178.6836  LR: 0.00001690  \n",
      "Epoch: [2][40/671] Elapsed 0m 9s (remain 2m 27s) Loss: 0.0972(0.1087) Grad: 70040.0000  LR: 0.00001673  \n",
      "Epoch: [2][60/671] Elapsed 0m 14s (remain 2m 26s) Loss: 0.2513(0.1041) Grad: 77911.4922  LR: 0.00001656  \n",
      "Epoch: [2][80/671] Elapsed 0m 19s (remain 2m 24s) Loss: 0.1597(0.1007) Grad: 53435.2539  LR: 0.00001638  \n",
      "Epoch: [2][100/671] Elapsed 0m 25s (remain 2m 21s) Loss: 0.0815(0.0986) Grad: 37518.0586  LR: 0.00001620  \n",
      "Epoch: [2][120/671] Elapsed 0m 30s (remain 2m 20s) Loss: 0.1188(0.0988) Grad: 53573.0820  LR: 0.00001601  \n",
      "Epoch: [2][140/671] Elapsed 0m 36s (remain 2m 16s) Loss: 0.0256(0.1000) Grad: 23392.3555  LR: 0.00001582  \n",
      "Epoch: [2][160/671] Elapsed 0m 41s (remain 2m 10s) Loss: 0.0897(0.0976) Grad: 28707.9062  LR: 0.00001563  \n",
      "Epoch: [2][180/671] Elapsed 0m 45s (remain 2m 3s) Loss: 0.0725(0.0994) Grad: 30963.5195  LR: 0.00001544  \n",
      "Epoch: [2][200/671] Elapsed 0m 50s (remain 1m 57s) Loss: 0.1215(0.0976) Grad: 31982.5723  LR: 0.00001524  \n",
      "Epoch: [2][220/671] Elapsed 0m 54s (remain 1m 51s) Loss: 0.0171(0.0971) Grad: 6141.2017  LR: 0.00001504  \n",
      "Epoch: [2][240/671] Elapsed 0m 59s (remain 1m 46s) Loss: 0.1059(0.0969) Grad: 30048.0098  LR: 0.00001483  \n",
      "Epoch: [2][260/671] Elapsed 1m 4s (remain 1m 41s) Loss: 0.0301(0.0987) Grad: 11153.1602  LR: 0.00001463  \n",
      "Epoch: [2][280/671] Elapsed 1m 9s (remain 1m 36s) Loss: 0.0828(0.0987) Grad: 44203.6133  LR: 0.00001442  \n",
      "Epoch: [2][300/671] Elapsed 1m 15s (remain 1m 32s) Loss: 0.2285(0.0990) Grad: 38877.5469  LR: 0.00001421  \n",
      "Epoch: [2][320/671] Elapsed 1m 20s (remain 1m 27s) Loss: 0.1327(0.0985) Grad: 52112.9297  LR: 0.00001399  \n",
      "Epoch: [2][340/671] Elapsed 1m 25s (remain 1m 22s) Loss: 0.1011(0.0977) Grad: 53116.3750  LR: 0.00001378  \n",
      "Epoch: [2][360/671] Elapsed 1m 30s (remain 1m 17s) Loss: 0.1841(0.0980) Grad: 69608.3203  LR: 0.00001356  \n",
      "Epoch: [2][380/671] Elapsed 1m 35s (remain 1m 12s) Loss: 0.1357(0.0977) Grad: 60244.7578  LR: 0.00001334  \n",
      "Epoch: [2][400/671] Elapsed 1m 41s (remain 1m 8s) Loss: 0.0901(0.0976) Grad: 39367.4492  LR: 0.00001312  \n",
      "Epoch: [2][420/671] Elapsed 1m 46s (remain 1m 3s) Loss: 0.0270(0.0988) Grad: 9297.9971  LR: 0.00001290  \n",
      "Epoch: [2][440/671] Elapsed 1m 51s (remain 0m 57s) Loss: 0.0740(0.0993) Grad: 33019.0430  LR: 0.00001267  \n",
      "Epoch: [2][460/671] Elapsed 1m 55s (remain 0m 52s) Loss: 0.1145(0.0990) Grad: 36457.9844  LR: 0.00001245  \n",
      "Epoch: [2][480/671] Elapsed 1m 59s (remain 0m 47s) Loss: 0.1068(0.0992) Grad: 35138.0781  LR: 0.00001222  \n",
      "Epoch: [2][500/671] Elapsed 2m 4s (remain 0m 42s) Loss: 0.1168(0.0994) Grad: 45506.6445  LR: 0.00001199  \n",
      "Epoch: [2][520/671] Elapsed 2m 9s (remain 0m 37s) Loss: 0.0966(0.1003) Grad: 47020.8008  LR: 0.00001176  \n",
      "Epoch: [2][540/671] Elapsed 2m 13s (remain 0m 32s) Loss: 0.0696(0.0993) Grad: 31791.0020  LR: 0.00001153  \n",
      "Epoch: [2][560/671] Elapsed 2m 18s (remain 0m 27s) Loss: 0.1134(0.0988) Grad: 35038.1445  LR: 0.00001130  \n",
      "Epoch: [2][580/671] Elapsed 2m 24s (remain 0m 22s) Loss: 0.0870(0.0992) Grad: 17724.4043  LR: 0.00001107  \n",
      "Epoch: [2][600/671] Elapsed 2m 28s (remain 0m 17s) Loss: 0.1501(0.0994) Grad: 55279.6172  LR: 0.00001083  \n",
      "Epoch: [2][620/671] Elapsed 2m 34s (remain 0m 12s) Loss: 0.0756(0.0998) Grad: 44706.5352  LR: 0.00001060  \n",
      "Epoch: [2][640/671] Elapsed 2m 39s (remain 0m 7s) Loss: 0.0483(0.0998) Grad: 21013.7871  LR: 0.00001037  \n",
      "Epoch: [2][660/671] Elapsed 2m 44s (remain 0m 2s) Loss: 0.1260(0.0996) Grad: 30835.0410  LR: 0.00001013  \n",
      "Epoch: [2][670/671] Elapsed 2m 47s (remain 0m 0s) Loss: 0.1003(0.0997) Grad: 22437.8574  LR: 0.00001002  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 51s) Loss: 0.2265(0.2265) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 17s) Loss: 0.1745(0.1287) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 12s) Loss: 0.1346(0.1261) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1204(0.1240) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0830(0.1215) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0606(0.1171) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0997  avg_val_loss: 0.1169  time: 189s\n",
      "Epoch 2 - Score: 0.4878  Scores: [0.418081505780061, 0.5574248344261303]\n",
      "Epoch 2 - Save Best Score: 0.4878 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0864(0.1169) \n",
      "Epoch: [3][0/671] Elapsed 0m 0s (remain 5m 7s) Loss: 0.0437(0.0437) Grad: inf  LR: 0.00001001  \n",
      "Epoch: [3][20/671] Elapsed 0m 6s (remain 3m 10s) Loss: 0.0583(0.0708) Grad: 66851.6016  LR: 0.00000977  \n",
      "Epoch: [3][40/671] Elapsed 0m 11s (remain 2m 56s) Loss: 0.0886(0.0659) Grad: 78661.3672  LR: 0.00000954  \n",
      "Epoch: [3][60/671] Elapsed 0m 16s (remain 2m 45s) Loss: 0.1080(0.0729) Grad: 68518.3750  LR: 0.00000930  \n",
      "Epoch: [3][80/671] Elapsed 0m 21s (remain 2m 34s) Loss: 0.0370(0.0705) Grad: 38602.2930  LR: 0.00000907  \n",
      "Epoch: [3][100/671] Elapsed 0m 26s (remain 2m 28s) Loss: 0.0673(0.0700) Grad: 47594.4688  LR: 0.00000884  \n",
      "Epoch: [3][120/671] Elapsed 0m 31s (remain 2m 25s) Loss: 0.0483(0.0703) Grad: 34136.6367  LR: 0.00000861  \n",
      "Epoch: [3][140/671] Elapsed 0m 37s (remain 2m 21s) Loss: 0.0953(0.0722) Grad: 78984.4219  LR: 0.00000838  \n",
      "Epoch: [3][160/671] Elapsed 0m 42s (remain 2m 13s) Loss: 0.0713(0.0718) Grad: 74498.6094  LR: 0.00000815  \n",
      "Epoch: [3][180/671] Elapsed 0m 46s (remain 2m 6s) Loss: 0.0404(0.0705) Grad: 21722.4590  LR: 0.00000792  \n",
      "Epoch: [3][200/671] Elapsed 0m 51s (remain 2m 1s) Loss: 0.0465(0.0689) Grad: 41819.5273  LR: 0.00000769  \n",
      "Epoch: [3][220/671] Elapsed 0m 56s (remain 1m 55s) Loss: 0.0293(0.0690) Grad: 48846.1797  LR: 0.00000746  \n",
      "Epoch: [3][240/671] Elapsed 1m 2s (remain 1m 50s) Loss: 0.0760(0.0687) Grad: 20296.5723  LR: 0.00000724  \n",
      "Epoch: [3][260/671] Elapsed 1m 6s (remain 1m 44s) Loss: 0.1648(0.0683) Grad: 116944.2500  LR: 0.00000701  \n",
      "Epoch: [3][280/671] Elapsed 1m 11s (remain 1m 39s) Loss: 0.0853(0.0681) Grad: 118837.5078  LR: 0.00000679  \n",
      "Epoch: [3][300/671] Elapsed 1m 16s (remain 1m 33s) Loss: 0.0223(0.0679) Grad: 22876.7852  LR: 0.00000657  \n",
      "Epoch: [3][320/671] Elapsed 1m 20s (remain 1m 28s) Loss: 0.0418(0.0676) Grad: 49432.1875  LR: 0.00000635  \n",
      "Epoch: [3][340/671] Elapsed 1m 26s (remain 1m 23s) Loss: 0.0180(0.0674) Grad: 34152.4766  LR: 0.00000613  \n",
      "Epoch: [3][360/671] Elapsed 1m 31s (remain 1m 18s) Loss: 0.0917(0.0671) Grad: 51996.2969  LR: 0.00000592  \n",
      "Epoch: [3][380/671] Elapsed 1m 35s (remain 1m 12s) Loss: 0.0429(0.0666) Grad: 48769.3594  LR: 0.00000571  \n",
      "Epoch: [3][400/671] Elapsed 1m 41s (remain 1m 8s) Loss: 0.0284(0.0664) Grad: 34114.2188  LR: 0.00000550  \n",
      "Epoch: [3][420/671] Elapsed 1m 45s (remain 1m 2s) Loss: 0.0550(0.0661) Grad: 74540.3828  LR: 0.00000529  \n",
      "Epoch: [3][440/671] Elapsed 1m 50s (remain 0m 57s) Loss: 0.0686(0.0660) Grad: 76681.1094  LR: 0.00000508  \n",
      "Epoch: [3][460/671] Elapsed 1m 55s (remain 0m 52s) Loss: 0.0424(0.0656) Grad: 18417.9062  LR: 0.00000488  \n",
      "Epoch: [3][480/671] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0543(0.0655) Grad: 56083.6641  LR: 0.00000468  \n",
      "Epoch: [3][500/671] Elapsed 2m 5s (remain 0m 42s) Loss: 0.0601(0.0655) Grad: 33888.4336  LR: 0.00000449  \n",
      "Epoch: [3][520/671] Elapsed 2m 10s (remain 0m 37s) Loss: 0.0499(0.0652) Grad: 63325.2461  LR: 0.00000429  \n",
      "Epoch: [3][540/671] Elapsed 2m 14s (remain 0m 32s) Loss: 0.0679(0.0650) Grad: 47322.2109  LR: 0.00000410  \n",
      "Epoch: [3][560/671] Elapsed 2m 19s (remain 0m 27s) Loss: 0.0596(0.0647) Grad: 49438.9141  LR: 0.00000392  \n",
      "Epoch: [3][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.0958(0.0650) Grad: 49501.2656  LR: 0.00000373  \n",
      "Epoch: [3][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.0482(0.0647) Grad: 66739.4688  LR: 0.00000355  \n",
      "Epoch: [3][620/671] Elapsed 2m 34s (remain 0m 12s) Loss: 0.0867(0.0643) Grad: 52040.7578  LR: 0.00000337  \n",
      "Epoch: [3][640/671] Elapsed 2m 40s (remain 0m 7s) Loss: 0.0432(0.0642) Grad: 41089.2695  LR: 0.00000320  \n",
      "Epoch: [3][660/671] Elapsed 2m 44s (remain 0m 2s) Loss: 0.0899(0.0641) Grad: 38520.0742  LR: 0.00000303  \n",
      "Epoch: [3][670/671] Elapsed 2m 47s (remain 0m 0s) Loss: 0.0550(0.0642) Grad: 41108.1953  LR: 0.00000295  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 51s) Loss: 0.2111(0.2111) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 17s) Loss: 0.1645(0.1213) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 12s) Loss: 0.1054(0.1172) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1205(0.1166) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0872(0.1136) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0707(0.1094) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0642  avg_val_loss: 0.1100  time: 189s\n",
      "Epoch 3 - Score: 0.4721  Scores: [0.4064078885423127, 0.537845010209294]\n",
      "Epoch 3 - Save Best Score: 0.4721 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0986(0.1100) \n",
      "Epoch: [4][0/671] Elapsed 0m 0s (remain 4m 37s) Loss: 0.0180(0.0180) Grad: 112857.5469  LR: 0.00000294  \n",
      "Epoch: [4][20/671] Elapsed 0m 4s (remain 2m 25s) Loss: 0.0464(0.0480) Grad: 48286.6055  LR: 0.00000278  \n",
      "Epoch: [4][40/671] Elapsed 0m 9s (remain 2m 31s) Loss: 0.0134(0.0497) Grad: 26515.8164  LR: 0.00000262  \n",
      "Epoch: [4][60/671] Elapsed 0m 14s (remain 2m 28s) Loss: 0.0305(0.0485) Grad: 28089.3906  LR: 0.00000246  \n",
      "Epoch: [4][80/671] Elapsed 0m 20s (remain 2m 26s) Loss: 0.0677(0.0490) Grad: 53605.9492  LR: 0.00000231  \n",
      "Epoch: [4][100/671] Elapsed 0m 25s (remain 2m 22s) Loss: 0.0135(0.0474) Grad: 27189.6641  LR: 0.00000216  \n",
      "Epoch: [4][120/671] Elapsed 0m 30s (remain 2m 17s) Loss: 0.0230(0.0470) Grad: 20783.8340  LR: 0.00000202  \n",
      "Epoch: [4][140/671] Elapsed 0m 34s (remain 2m 11s) Loss: 0.0212(0.0469) Grad: 33439.4102  LR: 0.00000188  \n",
      "Epoch: [4][160/671] Elapsed 0m 39s (remain 2m 4s) Loss: 0.0261(0.0468) Grad: 36437.8906  LR: 0.00000175  \n",
      "Epoch: [4][180/671] Elapsed 0m 44s (remain 2m 0s) Loss: 0.0493(0.0478) Grad: 60436.2891  LR: 0.00000162  \n",
      "Epoch: [4][200/671] Elapsed 0m 49s (remain 1m 56s) Loss: 0.0322(0.0481) Grad: 28601.0332  LR: 0.00000149  \n",
      "Epoch: [4][220/671] Elapsed 0m 55s (remain 1m 52s) Loss: 0.1507(0.0492) Grad: 53086.2344  LR: 0.00000137  \n",
      "Epoch: [4][240/671] Elapsed 0m 59s (remain 1m 46s) Loss: 0.0727(0.0491) Grad: 56868.8398  LR: 0.00000125  \n",
      "Epoch: [4][260/671] Elapsed 1m 4s (remain 1m 41s) Loss: 0.0792(0.0486) Grad: 66241.7812  LR: 0.00000114  \n",
      "Epoch: [4][280/671] Elapsed 1m 8s (remain 1m 35s) Loss: 0.0300(0.0489) Grad: 35849.9766  LR: 0.00000104  \n",
      "Epoch: [4][300/671] Elapsed 1m 15s (remain 1m 32s) Loss: 0.1017(0.0485) Grad: 58077.7930  LR: 0.00000094  \n",
      "Epoch: [4][320/671] Elapsed 1m 19s (remain 1m 26s) Loss: 0.0408(0.0485) Grad: 53855.2695  LR: 0.00000084  \n",
      "Epoch: [4][340/671] Elapsed 1m 24s (remain 1m 22s) Loss: 0.0551(0.0482) Grad: 39691.6719  LR: 0.00000075  \n",
      "Epoch: [4][360/671] Elapsed 1m 29s (remain 1m 17s) Loss: 0.0489(0.0483) Grad: 51087.9727  LR: 0.00000066  \n",
      "Epoch: [4][380/671] Elapsed 1m 34s (remain 1m 11s) Loss: 0.0589(0.0484) Grad: 30825.5781  LR: 0.00000058  \n",
      "Epoch: [4][400/671] Elapsed 1m 39s (remain 1m 7s) Loss: 0.0189(0.0486) Grad: 39155.0312  LR: 0.00000051  \n",
      "Epoch: [4][420/671] Elapsed 1m 44s (remain 1m 2s) Loss: 0.0344(0.0482) Grad: 47449.3633  LR: 0.00000043  \n",
      "Epoch: [4][440/671] Elapsed 1m 50s (remain 0m 57s) Loss: 0.0255(0.0479) Grad: 20748.8906  LR: 0.00000037  \n",
      "Epoch: [4][460/671] Elapsed 1m 55s (remain 0m 52s) Loss: 0.0461(0.0481) Grad: 34622.7734  LR: 0.00000031  \n",
      "Epoch: [4][480/671] Elapsed 2m 0s (remain 0m 47s) Loss: 0.0736(0.0482) Grad: 60358.9727  LR: 0.00000025  \n",
      "Epoch: [4][500/671] Elapsed 2m 4s (remain 0m 42s) Loss: 0.0274(0.0482) Grad: 31714.3203  LR: 0.00000020  \n",
      "Epoch: [4][520/671] Elapsed 2m 10s (remain 0m 37s) Loss: 0.0234(0.0482) Grad: 15818.0527  LR: 0.00000016  \n",
      "Epoch: [4][540/671] Elapsed 2m 14s (remain 0m 32s) Loss: 0.0976(0.0480) Grad: 73265.1406  LR: 0.00000012  \n",
      "Epoch: [4][560/671] Elapsed 2m 20s (remain 0m 27s) Loss: 0.0483(0.0485) Grad: 31228.1621  LR: 0.00000009  \n",
      "Epoch: [4][580/671] Elapsed 2m 25s (remain 0m 22s) Loss: 0.0334(0.0486) Grad: 27318.4961  LR: 0.00000006  \n",
      "Epoch: [4][600/671] Elapsed 2m 30s (remain 0m 17s) Loss: 0.0554(0.0485) Grad: 36363.0156  LR: 0.00000004  \n",
      "Epoch: [4][620/671] Elapsed 2m 35s (remain 0m 12s) Loss: 0.0762(0.0482) Grad: 49039.0078  LR: 0.00000002  \n",
      "Epoch: [4][640/671] Elapsed 2m 41s (remain 0m 7s) Loss: 0.0591(0.0482) Grad: 28273.7852  LR: 0.00000001  \n",
      "Epoch: [4][660/671] Elapsed 2m 46s (remain 0m 2s) Loss: 0.0521(0.0482) Grad: 35747.6523  LR: 0.00000000  \n",
      "Epoch: [4][670/671] Elapsed 2m 49s (remain 0m 0s) Loss: 0.0657(0.0483) Grad: 29360.1797  LR: 0.00000000  \n",
      "EVAL: [0/112] Elapsed 0m 0s (remain 0m 49s) Loss: 0.2036(0.2036) \n",
      "EVAL: [20/112] Elapsed 0m 3s (remain 0m 17s) Loss: 0.1651(0.1214) \n",
      "EVAL: [40/112] Elapsed 0m 7s (remain 0m 12s) Loss: 0.1078(0.1169) \n",
      "EVAL: [60/112] Elapsed 0m 11s (remain 0m 9s) Loss: 0.1231(0.1165) \n",
      "EVAL: [80/112] Elapsed 0m 14s (remain 0m 5s) Loss: 0.0937(0.1136) \n",
      "EVAL: [100/112] Elapsed 0m 18s (remain 0m 2s) Loss: 0.0713(0.1094) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0483  avg_val_loss: 0.1099  time: 190s\n",
      "Epoch 4 - Score: 0.4713  Scores: [0.4054812785432832, 0.5371189779973361]\n",
      "Epoch 4 - Save Best Score: 0.4713 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [111/112] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0937(0.1099) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 0.4713  Scores: [0.4054812785432832, 0.5371189779973361]\n",
      "========== CV ==========\n",
      "Score: 0.4667  Scores: [0.397662702749927, 0.5357621090834028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 Experiment: base-roberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b30aef794c14a65a09b96b42b762389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 512\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f2c8672df547ee98a1939e12a4c3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90da044ae5d4c26b629e6849a04df2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> fold <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(config.n_fold):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Fold: {</span>fold<span style=\"color: #808000; text-decoration-color: #808000\">} Experiment: {</span>model_config.experiment_name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> fold <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config.trn_fold:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>35 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>_oof_df = train_loop(model_config, train, fold)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>oof_df = pd.concat([oof_df, _oof_df])                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>LOGGER.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"========== fold: {</span>fold<span style=\"color: #808000; text-decoration-color: #808000\">} result ==========\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>get_result(_oof_df)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_loop</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">97</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>start_time = time.time()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># train</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 97 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, sche   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># eval</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_fn</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>labels = labels.to(device)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch_size = labels.size(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.cuda.amp.autocast(enabled=config.apex):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>y_preds = model(inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = criterion(y_preds, labels)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> config.gradient_accumulation_steps &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = loss / config.gradient_accumulation_steps                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">60</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> feature                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">58 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">59 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>60 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>feature = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.feature(inputs)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fc(feature)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">62 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> output                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module.weight.data.fill_(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span>)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(**inputs)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>last_hidden_states = outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>feature = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pool(last_hidden_states, inputs[<span style=\"color: #808000; text-decoration-color: #808000\">'attention_mask'</span>])                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> feature                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">852</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 849 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>inputs_embeds=inputs_embeds,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>past_key_values_length=past_key_values_length,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 851 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 852 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 853 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>embedding_output,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=extended_attention_mask,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 855 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>head_mask=head_mask,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">527</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 524 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>encoder_attention_mask,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 525 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 526 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 527 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = layer_module(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>attention_mask,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>layer_head_mask,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">411</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>) -&gt; Tuple[torch.Tensor]:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 409 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># decoder uni-directional self-attention cached key/values tuple is at positions</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>self_attn_past_key_value = past_key_value[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_key_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 411 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>self_attention_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attention(                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hidden_states,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 413 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 414 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>head_mask,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">347</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>past_key_value,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output_attentions,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 346 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 347 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attention_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output(self_outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], hidden_states)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = (attention_output,) + self_outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:]  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># add attentions if we output </span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 349 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> outputs                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 350 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">296</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 293 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dropout = nn.Dropout(config.hidden_dropout_prob)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 294 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 295 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -&gt; torch.  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 296 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dense(hidden_states)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 297 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dropout(hidden_states)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 298 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.LayerNorm(hidden_states + input_tensor)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 299 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> hidden_states                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">'in_features={}, out_features={}, bias={}'</span>.format(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> \n",
       "transpose_mat2 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> m <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> n <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> mat1_ld <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> mat2_ld <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> result_ld <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> abcType <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> computeType <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span> scaleType <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m35\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m fold \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(config.n_fold):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFold: \u001b[0m\u001b[33m{\u001b[0mfold\u001b[33m}\u001b[0m\u001b[33m Experiment: \u001b[0m\u001b[33m{\u001b[0mmodel_config.experiment_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m fold \u001b[95min\u001b[0m config.trn_fold:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m35 \u001b[2m│   │   │   \u001b[0m_oof_df = train_loop(model_config, train, fold)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   \u001b[0moof_df = pd.concat([oof_df, _oof_df])                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   │   \u001b[0mLOGGER.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m========== fold: \u001b[0m\u001b[33m{\u001b[0mfold\u001b[33m}\u001b[0m\u001b[33m result ==========\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   │   │   \u001b[0mget_result(_oof_df)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain_loop\u001b[0m:\u001b[94m97\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# train\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   \u001b[0mavg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, sche   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# eval\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0mavg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain_fn\u001b[0m:\u001b[94m14\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0mlabels = labels.to(device)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0mbatch_size = labels.size(\u001b[94m0\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.cuda.amp.autocast(enabled=config.apex):                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m14 \u001b[2m│   │   │   \u001b[0my_preds = model(inputs)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = criterion(y_preds, labels)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m config.gradient_accumulation_steps > \u001b[94m1\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = loss / config.gradient_accumulation_steps                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m60\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m57 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m feature                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m58 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m59 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, inputs):                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m60 \u001b[2m│   │   \u001b[0mfeature = \u001b[96mself\u001b[0m.feature(inputs)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m61 \u001b[0m\u001b[2m│   │   \u001b[0moutput = \u001b[96mself\u001b[0m.fc(feature)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m62 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m output                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m63 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfeature\u001b[0m:\u001b[94m54\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodule.weight.data.fill_(\u001b[94m1.0\u001b[0m)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfeature\u001b[0m(\u001b[96mself\u001b[0m, inputs):                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m54 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.model(**inputs)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   │   \u001b[0mlast_hidden_states = outputs[\u001b[94m0\u001b[0m]                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m56 \u001b[0m\u001b[2m│   │   \u001b[0mfeature = \u001b[96mself\u001b[0m.pool(last_hidden_states, inputs[\u001b[33m'\u001b[0m\u001b[33mattention_mask\u001b[0m\u001b[33m'\u001b[0m])                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m57 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m feature                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m852\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds=inputs_embeds,                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values_length=past_key_values_length,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 851 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 852 \u001b[2m│   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 853 \u001b[0m\u001b[2m│   │   │   \u001b[0membedding_output,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=extended_attention_mask,                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 855 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m527\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 524 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_attention_mask,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 525 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 526 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 527 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = layer_module(                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlayer_head_mask,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m411\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2m│   \u001b[0m) -> Tuple[torch.Tensor]:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 409 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# decoder uni-directional self-attention cached key/values tuple is at positions\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   \u001b[0mself_attn_past_key_value = past_key_value[:\u001b[94m2\u001b[0m] \u001b[94mif\u001b[0m past_key_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 411 \u001b[2m│   │   \u001b[0mself_attention_outputs = \u001b[96mself\u001b[0m.attention(                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 413 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 414 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m347\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 344 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_value,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 345 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput_attentions,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 346 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 347 \u001b[2m│   │   \u001b[0mattention_output = \u001b[96mself\u001b[0m.output(self_outputs[\u001b[94m0\u001b[0m], hidden_states)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 348 \u001b[0m\u001b[2m│   │   \u001b[0moutputs = (attention_output,) + self_outputs[\u001b[94m1\u001b[0m:]  \u001b[2m# add attentions if we output \u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 349 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m outputs                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 350 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m296\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 293 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.dropout = nn.Dropout(config.hidden_dropout_prob)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 294 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 295 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 296 \u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.dense(hidden_states)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 297 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.dropout(hidden_states)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 298 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.LayerNorm(hidden_states + input_tensor)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 299 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m hidden_states                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, bias=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 \u001b[1;36m1\u001b[0m \n",
       "transpose_mat2 \u001b[1;36m0\u001b[0m m \u001b[1;36m768\u001b[0m n \u001b[1;36m768\u001b[0m k \u001b[1;36m768\u001b[0m mat1_ld \u001b[1;36m768\u001b[0m mat2_ld \u001b[1;36m768\u001b[0m result_ld \u001b[1;36m768\u001b[0m abcType \u001b[1;36m2\u001b[0m computeType \u001b[1;36m68\u001b[0m scaleType \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_result(oof_df):\n",
    "    labels = oof_df[config.target_cols].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in config.target_cols]].values\n",
    "    score, scores = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
    "    \n",
    "config_list = [\n",
    "    {\n",
    "    'experiment_name': \"base-deberta\",\n",
    "    'model': 'microsoft/deberta-v3-base',\n",
    "    'batch_size': 8,\n",
    "    }, \n",
    "    {\n",
    "    'experiment_name': \"base-roberta\",\n",
    "    'model': 'roberta-base',\n",
    "    'batch_size': 8,\n",
    "    }, \n",
    "    {\n",
    "    'experiment_name': \"albert-base-v2\",\n",
    "    'model': 'albert-base-v2',\n",
    "    'batch_size': 8,\n",
    "    }, \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for config_dict in config_list:\n",
    "    # Create an instance of Config using the dictionary\n",
    "    model_config = Config(**config_dict)\n",
    "\n",
    "    oof_df = pd.DataFrame()\n",
    "    for fold in range(config.n_fold):\n",
    "        print(f\"Fold: {fold} Experiment: {model_config.experiment_name}\")\n",
    "        if fold in config.trn_fold:\n",
    "            _oof_df = train_loop(model_config, train, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcca5c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3179.165096,
   "end_time": "2023-08-19T12:46:43.357489",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-19T11:53:44.192393",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "022dc80d6a254f95b2c51524f60c7535": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "059f3fb1c7314be9aa920cfe1a3efb0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc273d8dc3624f8fa12cb97b37932a70",
       "placeholder": "​",
       "style": "IPY_MODEL_14c39bb00d7b4a63bd2a7316005817ad",
       "value": "100%"
      }
     },
     "07f74af6b0b54484b2b69daf1e315502": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "09c4dbd1d3a54a6e940410cfb8b1fd88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b91803b2ce24bd0a9402c26134bcfb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ac8a3173c963487c9c4afaaae0b39ad3",
       "placeholder": "​",
       "style": "IPY_MODEL_e297d6f7fecf478ebfdf904d913e6afb",
       "value": " 7165/7165 [00:02&lt;00:00, 2909.66it/s]"
      }
     },
     "0ee3d8647628465d84141fd5911392eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80bed13b4fe9488f86a65ae59437a410",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f027b77ed87b45a88f24b1354e2f954c",
       "value": 579.0
      }
     },
     "0ffa4b9db2ef4553bd65ec1403957717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_392fc62a03454a90a4ca40ad78282389",
       "placeholder": "​",
       "style": "IPY_MODEL_63e482fd9d1746d58ee64ec28081ca4c",
       "value": " 7165/7165 [00:02&lt;00:00, 3219.07it/s]"
      }
     },
     "105f1b0957ca4ffd812378a4818483a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9ee2f2f5682444e834d50394aa4172b",
       "placeholder": "​",
       "style": "IPY_MODEL_f03f255dfed7422eb606a5206d0afeda",
       "value": " 371M/371M [00:04&lt;00:00, 73.7MB/s]"
      }
     },
     "1212dcbfd8e34ace971ae9dd38abf819": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1221edafb05e45f4bab6eef95646c022": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "12fb487aaa4a458895c5bbec305759e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "136b53478b5147ed98e14d2f2f2b100e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14c39bb00d7b4a63bd2a7316005817ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "14c79c39570f4b8e9d0c8caabfcfa31f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "162805a986ba4347b8bfb400c6f8010c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e4293dc00d349bd9dee3191ad8851b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_847ab69ee5be4cbc9ad3febbc234d842",
       "max": 498818054.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_764bd4d387f24bc3aaad74278ae3f62f",
       "value": 498818054.0
      }
     },
     "22fb87d749d548e6913c09491f7b11b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25ac1661513544128a4b049335d5b916": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b30aef794c14a65a09b96b42b762389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d2e5e880c0d49f29126a6d21287c859",
        "IPY_MODEL_6005544398c94f96ae777156f596e64a",
        "IPY_MODEL_c08424e361a04ff6a86e200f8e2435be"
       ],
       "layout": "IPY_MODEL_7b11c72957bf40638fb2c9a4963e2b09"
      }
     },
     "2ba4c2da05274b13a5b4cd69bd080637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2d209361df424104ba8d15cb10a588a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30e035471f7d4d5abd5f2d8f02148b93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3203a17c070e431aa89f4f4e6a3838bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc4c3a0f93964033920c0296d3045f24",
       "placeholder": "​",
       "style": "IPY_MODEL_46a213fd28cb46ee9672699f08e60c04",
       "value": " 579/579 [00:00&lt;00:00, 39.0kB/s]"
      }
     },
     "33fc2e7939684c9aa107b01f745faced": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de2d8ef6ce38437a9e7c9a8d9c7abe65",
       "placeholder": "​",
       "style": "IPY_MODEL_bbdbd116391140f98ab0dc0ebdf7eccb",
       "value": " 7165/7165 [00:02&lt;00:00, 3003.42it/s]"
      }
     },
     "346fe1f5f7fa4e73b71563273f244102": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3785597ec7754442baf449040d0e88cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "392fc62a03454a90a4ca40ad78282389": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40dd0689205d49f89f314928566f58f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4fb49f439014934a3b05ef3b78483cb",
       "placeholder": "​",
       "style": "IPY_MODEL_4a45587060a3465792d70a2b112690c0",
       "value": " 499M/499M [00:06&lt;00:00, 79.6MB/s]"
      }
     },
     "410bbe60b165418b85dfc8624900559f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d9da4783ced64a5d9c763f072d5b4daf",
       "placeholder": "​",
       "style": "IPY_MODEL_8d5a83cc4a87430f9da952058f013cdb",
       "value": "Downloading (…)okenizer_config.json: 100%"
      }
     },
     "428abd5cb7404067ad3b089df92046a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d755f5d1dcc4cc690702d07b7546dc1",
       "max": 7165.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_07f74af6b0b54484b2b69daf1e315502",
       "value": 7165.0
      }
     },
     "46a213fd28cb46ee9672699f08e60c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "49a5a6b5547342e9beecd29e22e7dedf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eac39785ce154e4f8af8769bcba44554",
       "placeholder": "​",
       "style": "IPY_MODEL_c815c9f4a6334bc5a27f77e9eaa26d4b",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 50.2MB/s]"
      }
     },
     "4a45587060a3465792d70a2b112690c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4cf20296a9eb4897860f45146a4be0d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4efa6544caf84c12bae5ce91cd3e05df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_059f3fb1c7314be9aa920cfe1a3efb0c",
        "IPY_MODEL_730807ad320148318a5190a0a738471a",
        "IPY_MODEL_532a62fa7e5e42608ccd47c471b9f5ae"
       ],
       "layout": "IPY_MODEL_e71243e549f04b469d18dfa021614870"
      }
     },
     "527e963700124574bfcc489454724ed5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "532a62fa7e5e42608ccd47c471b9f5ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_adfd013f439b46adadd70cbb8e74de2f",
       "placeholder": "​",
       "style": "IPY_MODEL_7e28e4c78c6a46b8bfb069fa69862df9",
       "value": " 7165/7165 [00:02&lt;00:00, 2727.51it/s]"
      }
     },
     "569ac6413704492699089172237945a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5cf8e489a64b4958a4e0738aaa2d552c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d755f5d1dcc4cc690702d07b7546dc1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5de76940831d4cfcbff5885bc270f1e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5e113a8bb0d14c8d8a715213d1d84e25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad20943701984e92947faa98fd19641d",
       "placeholder": "​",
       "style": "IPY_MODEL_960f61a521c442ba828fe410abb74a61",
       "value": "Downloading spm.model: 100%"
      }
     },
     "5f59ea93532d4e2a80e5d49abd26e886": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6005544398c94f96ae777156f596e64a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0e4559b7fcc4efc9a79ce040a43264e",
       "max": 7165.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_808e901ac15347bba59c6d7f1b8f80c4",
       "value": 7165.0
      }
     },
     "63e482fd9d1746d58ee64ec28081ca4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "64dbd663cd5a4f1791b65f0c25863ecc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ef15f2764d14af5ab06a12c256ca639": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "730807ad320148318a5190a0a738471a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9f73f3fb5b50477d83a053d5c334183f",
       "max": 7165.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9abd16fc1f554c8c939c56205b3d35ff",
       "value": 7165.0
      }
     },
     "764bd4d387f24bc3aaad74278ae3f62f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "768eec5b85444277b1d5d6357a0d2546": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a47a9841077412f9056af053ce52e02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1212dcbfd8e34ace971ae9dd38abf819",
       "placeholder": "​",
       "style": "IPY_MODEL_22fb87d749d548e6913c09491f7b11b4",
       "value": "Downloading (…)lve/main/config.json: 100%"
      }
     },
     "7b11c72957bf40638fb2c9a4963e2b09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7de23518ac0e4136bb06a58a215afacc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d209361df424104ba8d15cb10a588a0",
       "max": 7165.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a4c829b14fab4c5ca3e03fabf376a711",
       "value": 7165.0
      }
     },
     "7e28e4c78c6a46b8bfb069fa69862df9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fae06733b23409cae6d2d64faf2d739": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3785597ec7754442baf449040d0e88cd",
       "max": 481.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c96539ec1dae435eb5276ad6a16be0e3",
       "value": 481.0
      }
     },
     "808e901ac15347bba59c6d7f1b8f80c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "80bed13b4fe9488f86a65ae59437a410": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "830620af4e58470581788400a79b1b0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "847ab69ee5be4cbc9ad3febbc234d842": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a816ee0b8cb412191efc2c600537e67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d2e5e880c0d49f29126a6d21287c859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fae5a0d2cf624375ab2de0935295a3b5",
       "placeholder": "​",
       "style": "IPY_MODEL_2ba4c2da05274b13a5b4cd69bd080637",
       "value": "100%"
      }
     },
     "8d5a83cc4a87430f9da952058f013cdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8defa56e949f401889b95a8c68e85208": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95ca79811e1e4e98babe27bf20456aa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "960f61a521c442ba828fe410abb74a61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9abd16fc1f554c8c939c56205b3d35ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9b01b5c566a641b5b28ea7cf7720dcd9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f73f3fb5b50477d83a053d5c334183f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4c829b14fab4c5ca3e03fabf376a711": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a5c1adc081e64e5c9a479c25c0fd3548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09c4dbd1d3a54a6e940410cfb8b1fd88",
       "placeholder": "​",
       "style": "IPY_MODEL_1221edafb05e45f4bab6eef95646c022",
       "value": "Downloading pytorch_model.bin: 100%"
      }
     },
     "a90da044ae5d4c26b629e6849a04df2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e9e50c1ce1eb4c18903c7d3161ee789c",
        "IPY_MODEL_1e4293dc00d349bd9dee3191ad8851b1",
        "IPY_MODEL_40dd0689205d49f89f314928566f58f8"
       ],
       "layout": "IPY_MODEL_768eec5b85444277b1d5d6357a0d2546"
      }
     },
     "a9265ef6a9a349df94f1d18bf5a0fd13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cb5822ba1c0b4a5ab35db9757a82e5de",
        "IPY_MODEL_7de23518ac0e4136bb06a58a215afacc",
        "IPY_MODEL_0b91803b2ce24bd0a9402c26134bcfb3"
       ],
       "layout": "IPY_MODEL_f33be97457fe4ebab0a600450d460b8e"
      }
     },
     "aa6104befa4c44ff835cda6661de4d34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ed76bd0a2162470f9b59e96141ca7267",
        "IPY_MODEL_0ee3d8647628465d84141fd5911392eb",
        "IPY_MODEL_3203a17c070e431aa89f4f4e6a3838bf"
       ],
       "layout": "IPY_MODEL_ebd9a43c96fd409fa4d0f2b194524e5c"
      }
     },
     "abceea1bd6444e2987873dee45c7dd50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ac8a3173c963487c9c4afaaae0b39ad3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad20943701984e92947faa98fd19641d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adfd013f439b46adadd70cbb8e74de2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afe52d76e7484d658af5fbec69da5b1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b21cb2626e8c435598aa17d29cf01a58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b7f7c2913a1c470fb2858ffc8d04c436": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_410bbe60b165418b85dfc8624900559f",
        "IPY_MODEL_cd9606f590ac43f4b81cff9ed583914d",
        "IPY_MODEL_ef2e619e63ac4eb8a6192b9d18e45d17"
       ],
       "layout": "IPY_MODEL_12fb487aaa4a458895c5bbec305759e7"
      }
     },
     "bbdbd116391140f98ab0dc0ebdf7eccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bd4d22e8ae014d3a98097cd862fb9af8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e57793b71dfb4b6487e0f10749605997",
       "placeholder": "​",
       "style": "IPY_MODEL_569ac6413704492699089172237945a4",
       "value": "100%"
      }
     },
     "c08424e361a04ff6a86e200f8e2435be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25ac1661513544128a4b049335d5b916",
       "placeholder": "​",
       "style": "IPY_MODEL_facac7cf21e147758ef8d5fd84282985",
       "value": " 7165/7165 [00:02&lt;00:00, 2864.91it/s]"
      }
     },
     "c80da7f819d640bbab9a19626e5e90d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c815c9f4a6334bc5a27f77e9eaa26d4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c8d6f9856be0461c8ffec9e45188d920": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc67ed8b62174956b30fe51e77d8c9f8",
        "IPY_MODEL_428abd5cb7404067ad3b089df92046a8",
        "IPY_MODEL_0ffa4b9db2ef4553bd65ec1403957717"
       ],
       "layout": "IPY_MODEL_e7f3344e58a445d09a6cb56194396da2"
      }
     },
     "c96539ec1dae435eb5276ad6a16be0e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cb5822ba1c0b4a5ab35db9757a82e5de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f59ea93532d4e2a80e5d49abd26e886",
       "placeholder": "​",
       "style": "IPY_MODEL_4cf20296a9eb4897860f45146a4be0d3",
       "value": "100%"
      }
     },
     "cc273d8dc3624f8fa12cb97b37932a70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc4c3a0f93964033920c0296d3045f24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc67ed8b62174956b30fe51e77d8c9f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_162805a986ba4347b8bfb400c6f8010c",
       "placeholder": "​",
       "style": "IPY_MODEL_abceea1bd6444e2987873dee45c7dd50",
       "value": "100%"
      }
     },
     "cd72b209656d4106ab40fbde25ee3a9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bd4d22e8ae014d3a98097cd862fb9af8",
        "IPY_MODEL_dce84b645b304ab9a2d661c2e2afd4c2",
        "IPY_MODEL_33fc2e7939684c9aa107b01f745faced"
       ],
       "layout": "IPY_MODEL_8defa56e949f401889b95a8c68e85208"
      }
     },
     "cd9606f590ac43f4b81cff9ed583914d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_30e035471f7d4d5abd5f2d8f02148b93",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ed8b11029e1b4f33b224ce1a113797d8",
       "value": 52.0
      }
     },
     "d097f81bd61340b6839a57b96fb38d63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a5c1adc081e64e5c9a479c25c0fd3548",
        "IPY_MODEL_d9b311401c164be583f607c457beda0e",
        "IPY_MODEL_105f1b0957ca4ffd812378a4818483a2"
       ],
       "layout": "IPY_MODEL_527e963700124574bfcc489454724ed5"
      }
     },
     "d4fb49f439014934a3b05ef3b78483cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9b311401c164be583f607c457beda0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a816ee0b8cb412191efc2c600537e67",
       "max": 371146213.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5de76940831d4cfcbff5885bc270f1e2",
       "value": 371146213.0
      }
     },
     "d9da4783ced64a5d9c763f072d5b4daf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dce84b645b304ab9a2d661c2e2afd4c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b01b5c566a641b5b28ea7cf7720dcd9",
       "max": 7165.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_95ca79811e1e4e98babe27bf20456aa2",
       "value": 7165.0
      }
     },
     "ddfdc0c4f675402c955daabd9c07e89a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_022dc80d6a254f95b2c51524f60c7535",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b21cb2626e8c435598aa17d29cf01a58",
       "value": 2464616.0
      }
     },
     "de2d8ef6ce38437a9e7c9a8d9c7abe65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df16c8eb1ad044d98be00a9956536f88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0e4559b7fcc4efc9a79ce040a43264e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2273e87a76e4f73b60ba498ec4f8604": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5e113a8bb0d14c8d8a715213d1d84e25",
        "IPY_MODEL_ddfdc0c4f675402c955daabd9c07e89a",
        "IPY_MODEL_49a5a6b5547342e9beecd29e22e7dedf"
       ],
       "layout": "IPY_MODEL_5cf8e489a64b4958a4e0738aaa2d552c"
      }
     },
     "e297d6f7fecf478ebfdf904d913e6afb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e57793b71dfb4b6487e0f10749605997": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e71243e549f04b469d18dfa021614870": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7f3344e58a445d09a6cb56194396da2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9e50c1ce1eb4c18903c7d3161ee789c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_346fe1f5f7fa4e73b71563273f244102",
       "placeholder": "​",
       "style": "IPY_MODEL_830620af4e58470581788400a79b1b0a",
       "value": "Downloading model.safetensors: 100%"
      }
     },
     "e9ee2f2f5682444e834d50394aa4172b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9f2c8672df547ee98a1939e12a4c3a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7a47a9841077412f9056af053ce52e02",
        "IPY_MODEL_7fae06733b23409cae6d2d64faf2d739",
        "IPY_MODEL_f78c2827aa6b4bb9a338966556d8ecd1"
       ],
       "layout": "IPY_MODEL_136b53478b5147ed98e14d2f2f2b100e"
      }
     },
     "eac39785ce154e4f8af8769bcba44554": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebd9a43c96fd409fa4d0f2b194524e5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed76bd0a2162470f9b59e96141ca7267": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6ef15f2764d14af5ab06a12c256ca639",
       "placeholder": "​",
       "style": "IPY_MODEL_afe52d76e7484d658af5fbec69da5b1b",
       "value": "Downloading (…)lve/main/config.json: 100%"
      }
     },
     "ed8b11029e1b4f33b224ce1a113797d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ef2e619e63ac4eb8a6192b9d18e45d17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df16c8eb1ad044d98be00a9956536f88",
       "placeholder": "​",
       "style": "IPY_MODEL_c80da7f819d640bbab9a19626e5e90d1",
       "value": " 52.0/52.0 [00:00&lt;00:00, 2.64kB/s]"
      }
     },
     "f027b77ed87b45a88f24b1354e2f954c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f03f255dfed7422eb606a5206d0afeda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f33be97457fe4ebab0a600450d460b8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f78c2827aa6b4bb9a338966556d8ecd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64dbd663cd5a4f1791b65f0c25863ecc",
       "placeholder": "​",
       "style": "IPY_MODEL_14c79c39570f4b8e9d0c8caabfcfa31f",
       "value": " 481/481 [00:00&lt;00:00, 27.1kB/s]"
      }
     },
     "facac7cf21e147758ef8d5fd84282985": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fae5a0d2cf624375ab2de0935295a3b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
